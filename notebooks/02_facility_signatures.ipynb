{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0aa7c3-aa67-4acc-9b71-3b6ca94f261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] C:\\Users\\Owner\\OneDrive\\NursingHomeData\\ownership-files\\ownership_combined.csv\n",
      "[hospital filter] dropped 656 facilities (flagged True) — kept 13419\n",
      "[snapshots built] rows: 39643\n",
      "[save] long : C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_long.csv  rows= 37374\n",
      "[save] wide : C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_wide_preview.csv  rows= 13419\n",
      "[diagnostic] total CCNs in raw: 14075\n",
      "[diagnostic] CCNs after hospital filter: 13419\n",
      "[diagnostic] CCNs removed by hospital filter: 656\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Facility Signatures Builder (Association-Date; Indirect→Direct→Partnership)\n",
    "# With hospital-based filter: drop CCNs where provider_resides_in_hospital == True\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import os, re, json, pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------- Config / Paths -----------------------------------\n",
    "ENV_DIR      = os.getenv(\"NH_DATA_DIR\", r\"C:\\Users\\Owner\\OneDrive\\NursingHomeData\")\n",
    "OWN_DIR      = pathlib.Path(ENV_DIR) / \"ownership-files\"\n",
    "INPUT_FP     = OWN_DIR / \"ownership_combined.csv\"\n",
    "\n",
    "# hospital-based CCNs file (built earlier)\n",
    "PROV_DIR     = pathlib.Path(r\"C:\\Users\\Owner\\OneDrive\\NursingHomeData\\provider-info-files\")\n",
    "HOSP_FP      = PROV_DIR / \"provider_resides_in_hospital_by_ccn.csv\"\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "while not (PROJECT_ROOT / \"data\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if not (PROJECT_ROOT / \"data\").is_dir():\n",
    "    PROJECT_ROOT = OWN_DIR.parent\n",
    "\n",
    "INTERIM_DIR  = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_LONG = INTERIM_DIR / \"facility_signatures_long.csv\"\n",
    "OUT_WIDE = INTERIM_DIR / \"facility_signatures_wide_preview.csv\"\n",
    "\n",
    "# -------------------------- Tunables -----------------------------------------\n",
    "LEVEL_PRIORITY   = [\"indirect\", \"direct\", \"partnership\"]\n",
    "ROUND_PCT        = 1\n",
    "TURNOVER_THRESH  = 0.50\n",
    "WIDE_MAX_GROUPS  = 8\n",
    "\n",
    "# -------------------------- Helpers ------------------------------------------\n",
    "SUFFIXES = r'\\b(INC|INCORPORATED|CORP|CORPORATION|LLC|L\\.L\\.C\\.|L\\.P\\.|LP|LLP|PLC|CO|COMPANY|HOLDINGS?|PARTNERS?|PARTNERSHIP|CAPITAL|INVESTMENTS?|TRUST|GROUP)\\b'\n",
    "\n",
    "def clean_owner_name(s: str) -> str:\n",
    "    if pd.isna(s) or not str(s).strip():\n",
    "        return \"\"\n",
    "    x = str(s).upper()\n",
    "    x = re.sub(r\"[.,&/()\\-']\", \" \", x)\n",
    "    x = re.sub(SUFFIXES, \"\", x)\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "    return x\n",
    "\n",
    "def level_bucket(role_val: str) -> str:\n",
    "    s = str(role_val).lower()\n",
    "    if \"indirect\" in s:  return \"indirect\"\n",
    "    if \"direct\"   in s:  return \"direct\"\n",
    "    if \"partner\"  in s:  return \"partnership\"\n",
    "    return \"\"\n",
    "\n",
    "def normalize_weights_allow_missing(df_block: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = df_block.copy()\n",
    "    g[\"ownership_percentage\"] = pd.to_numeric(g[\"ownership_percentage\"], errors=\"coerce\")\n",
    "\n",
    "    agg_num = (\n",
    "        g.groupby(\"owner_name_norm\", as_index=False)[\"ownership_percentage\"]\n",
    "         .sum(min_count=1)\n",
    "    )\n",
    "\n",
    "    has_numeric   = agg_num[\"ownership_percentage\"].notna().any()\n",
    "    total_numeric = agg_num[\"ownership_percentage\"].fillna(0).sum()\n",
    "\n",
    "    if has_numeric and total_numeric > 0:\n",
    "        vec = agg_num[agg_num[\"ownership_percentage\"].notna()].copy()\n",
    "        vec[\"ownership_percentage\"] = vec[\"ownership_percentage\"] * (100.0 / total_numeric)\n",
    "    else:\n",
    "        owners = agg_num[\"owner_name_norm\"].tolist()\n",
    "        if not owners:\n",
    "            return pd.DataFrame(columns=[\"owner_name_norm\",\"ownership_percentage\"])\n",
    "        equal = 100.0 / len(owners)\n",
    "        vec = pd.DataFrame({\"owner_name_norm\": owners,\n",
    "                            \"ownership_percentage\": [equal]*len(owners)})\n",
    "\n",
    "    vec[\"ownership_percentage\"] = vec[\"ownership_percentage\"].round(ROUND_PCT)\n",
    "    tot2 = vec[\"ownership_percentage\"].sum()\n",
    "    if tot2 > 0:\n",
    "        vec[\"ownership_percentage\"] = (vec[\"ownership_percentage\"] * (100.0 / tot2)).round(ROUND_PCT)\n",
    "\n",
    "    vec = vec[vec[\"ownership_percentage\"] > 0].copy()\n",
    "    if vec.empty:\n",
    "        owners = agg_num[\"owner_name_norm\"].tolist()\n",
    "        equal = 100.0 / len(owners)\n",
    "        vec = pd.DataFrame({\"owner_name_norm\": owners,\n",
    "                            \"ownership_percentage\": [round(equal, ROUND_PCT)]*len(owners)})\n",
    "    return vec.sort_values([\"ownership_percentage\",\"owner_name_norm\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "def pct_overlap(prev_map: dict, curr_map: dict) -> float:\n",
    "    names = set(prev_map) | set(curr_map)\n",
    "    overlap = 0.0\n",
    "    for n in names:\n",
    "        overlap += min(prev_map.get(n, 0.0), curr_map.get(n, 0.0))\n",
    "    return max(0.0, min(overlap / 100.0, 1.0))\n",
    "\n",
    "# -------------------------- Load & Prepare -----------------------------------\n",
    "print(\"[load]\", INPUT_FP)\n",
    "df = pd.read_csv(INPUT_FP, low_memory=False)\n",
    "\n",
    "needed = {\"cms_certification_number\", \"role\", \"owner_name\", \"ownership_percentage\", \"association_date\"}\n",
    "missing = needed - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Normalize CCN & dates\n",
    "df[\"cms_certification_number\"] = df[\"cms_certification_number\"].astype(str).str.extract(r\"(\\d+)\")[0].str.zfill(6)\n",
    "df[\"association_date\"] = pd.to_datetime(df[\"association_date\"], errors=\"coerce\")\n",
    "\n",
    "# Keep rows w/ valid date (we do NOT drop for missing ownership %)\n",
    "df = df.dropna(subset=[\"association_date\"]).copy()\n",
    "\n",
    "# -------- NEW: load hospital-based CCNs and filter them out --------\n",
    "if HOSP_FP.exists():\n",
    "    hosp = pd.read_csv(HOSP_FP, dtype={\"cms_certification_number\":\"string\"})\n",
    "    if \"provider_resides_in_hospital\" not in hosp.columns:\n",
    "        raise ValueError(f\"{HOSP_FP} missing 'provider_resides_in_hospital' column\")\n",
    "    hosp[\"cms_certification_number\"] = hosp[\"cms_certification_number\"].astype(str).str.extract(r\"(\\d+)\")[0].str.zfill(6)\n",
    "\n",
    "    # Normalize boolean (accept strings)\n",
    "    def to_bool(x):\n",
    "        if pd.isna(x): return pd.NA\n",
    "        s = str(x).strip().lower()\n",
    "        if s in {\"1\",\"y\",\"yes\",\"true\",\"t\"}:  return True\n",
    "        if s in {\"0\",\"n\",\"no\",\"false\",\"f\"}:  return False\n",
    "        return pd.NA\n",
    "    hosp[\"provider_resides_in_hospital\"] = hosp[\"provider_resides_in_hospital\"].map(to_bool)\n",
    "\n",
    "    drop_ccns = set(hosp.loc[hosp[\"provider_resides_in_hospital\"] == True, \"cms_certification_number\"])\n",
    "    before_fac = df[\"cms_certification_number\"].nunique()\n",
    "    df = df[~df[\"cms_certification_number\"].isin(drop_ccns)].copy()\n",
    "    after_fac  = df[\"cms_certification_number\"].nunique()\n",
    "    print(f\"[hospital filter] dropped {before_fac - after_fac} facilities (flagged True) — kept {after_fac}\")\n",
    "else:\n",
    "    print(f\"[hospital filter] WARNING: {HOSP_FP} not found — no CCNs filtered\")\n",
    "\n",
    "# Normalize owner names and levels\n",
    "df[\"owner_name_norm\"] = df[\"owner_name\"].map(clean_owner_name)\n",
    "df[\"level\"] = df[\"role\"].map(level_bucket)\n",
    "\n",
    "# -------------------------- Build Snapshots ----------------------------------\n",
    "snapshots = []\n",
    "for (ccn, adate), g in df.groupby([\"cms_certification_number\",\"association_date\"], sort=True):\n",
    "    chosen = None\n",
    "    for lvl in LEVEL_PRIORITY:\n",
    "        gl = g[g[\"level\"] == lvl]\n",
    "        if len(gl):\n",
    "            chosen = (lvl, gl)\n",
    "            break\n",
    "    if chosen is None:\n",
    "        continue\n",
    "\n",
    "    lvl, gl = chosen\n",
    "    vec = normalize_weights_allow_missing(gl[[\"owner_name_norm\",\"ownership_percentage\"]].copy())\n",
    "    if vec.empty:\n",
    "        owners = gl[\"owner_name_norm\"].dropna().unique().tolist()\n",
    "        if not owners:\n",
    "            continue\n",
    "        equal = 100.0 / len(owners)\n",
    "        vec = pd.DataFrame({\"owner_name_norm\": owners,\n",
    "                            \"ownership_percentage\": [round(equal, ROUND_PCT)]*len(owners)})\n",
    "\n",
    "    weight_map = dict(zip(vec[\"owner_name_norm\"], vec[\"ownership_percentage\"].astype(float)))\n",
    "    snapshots.append({\n",
    "        \"cms_certification_number\": ccn,\n",
    "        \"association_date\": adate,\n",
    "        \"source_level\": lvl,\n",
    "        \"weights\": weight_map\n",
    "    })\n",
    "\n",
    "snapshots_df = pd.DataFrame(snapshots).sort_values([\"cms_certification_number\",\"association_date\"]).reset_index(drop=True)\n",
    "print(\"[snapshots built] rows:\", len(snapshots_df))\n",
    "\n",
    "# -------------------------- Grouping into Stable Regimes ---------------------\n",
    "long_rows = []\n",
    "for ccn, g in snapshots_df.groupby(\"cms_certification_number\", sort=True):\n",
    "    g = g.sort_values(\"association_date\").reset_index(drop=True)\n",
    "    if g.empty: continue\n",
    "\n",
    "    group_n     = 1\n",
    "    group_start = g.loc[0, \"association_date\"]\n",
    "    group_level = g.loc[0, \"source_level\"]\n",
    "    prev_weights = g.loc[0, \"weights\"]\n",
    "\n",
    "    def hhi_from_map(wm: dict) -> float:\n",
    "        return round(sum((p/100.0)**2 for p in wm.values()), 4)\n",
    "\n",
    "    long_rows.append({\n",
    "        \"cms_certification_number\": ccn,\n",
    "        \"group_n\": group_n,\n",
    "        \"start\": group_start,\n",
    "        \"end\": pd.NaT,\n",
    "        \"source_level\": group_level,\n",
    "        \"names_list\": json.dumps(list(prev_weights.keys()), separators=(\",\", \":\")),\n",
    "        \"pcts_list\": json.dumps(list(prev_weights.values()), separators=(\",\", \":\")),\n",
    "        \"owner_count\": len(prev_weights),\n",
    "        \"hhi\": hhi_from_map(prev_weights),\n",
    "    })\n",
    "\n",
    "    for i in range(1, len(g)):\n",
    "        curr_weights = g.loc[i, \"weights\"]\n",
    "        ov = pct_overlap(prev_weights, curr_weights)\n",
    "        turnover = 1.0 - ov\n",
    "\n",
    "        if turnover >= TURNOVER_THRESH:\n",
    "            long_rows[-1][\"end\"] = g.loc[i-1, \"association_date\"]\n",
    "            group_n += 1\n",
    "            group_start = g.loc[i, \"association_date\"]\n",
    "            group_level = g.loc[i, \"source_level\"]\n",
    "            long_rows.append({\n",
    "                \"cms_certification_number\": ccn,\n",
    "                \"group_n\": group_n,\n",
    "                \"start\": group_start,\n",
    "                \"end\": pd.NaT,\n",
    "                \"source_level\": group_level,\n",
    "                \"names_list\": json.dumps(list(curr_weights.keys()), separators=(\",\", \":\")),\n",
    "                \"pcts_list\": json.dumps(list(curr_weights.values()), separators=(\",\", \":\")),\n",
    "                \"owner_count\": len(curr_weights),\n",
    "                \"hhi\": hhi_from_map(curr_weights),\n",
    "            })\n",
    "            prev_weights = curr_weights\n",
    "        else:\n",
    "            prev_weights = curr_weights\n",
    "\n",
    "    long_rows[-1][\"end\"] = g.loc[len(g)-1, \"association_date\"]\n",
    "\n",
    "long_df = pd.DataFrame(long_rows).sort_values([\"cms_certification_number\",\"group_n\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------------- Wide Preview (QC only) ---------------------------\n",
    "def as_label(names_json, pcts_json, k=12):\n",
    "    names = json.loads(names_json)\n",
    "    pcts  = json.loads(pcts_json)\n",
    "    pairs = [f\"{n} ({round(p, ROUND_PCT)}%)\" for n, p in zip(names, pcts)]\n",
    "    return \"; \".join(pairs[:k])\n",
    "\n",
    "if not long_df.empty:\n",
    "    wide_blocks = []\n",
    "    for ccn, g in long_df.groupby(\"cms_certification_number\"):\n",
    "        g = g.sort_values(\"group_n\")\n",
    "        row = {\"cms_certification_number\": ccn}\n",
    "        for _, r in g.head(WIDE_MAX_GROUPS).iterrows():\n",
    "            n = int(r[\"group_n\"])\n",
    "            row[f\"group{n}_start\"] = pd.to_datetime(r[\"start\"]).date()\n",
    "            row[f\"group{n}_end\"]   = pd.to_datetime(r[\"end\"]).date()\n",
    "            row[f\"group{n}_level\"] = r[\"source_level\"]\n",
    "            row[f\"group{n}_names\"] = as_label(r[\"names_list\"], r[\"pcts_list\"])\n",
    "            row[f\"group{n}_pcts\"]  = \",\".join(map(lambda x: str(int(round(x,0))), json.loads(r[\"pcts_list\"])))\n",
    "        wide_blocks.append(row)\n",
    "    wide_df = pd.DataFrame(wide_blocks).sort_values(\"cms_certification_number\").reset_index(drop=True)\n",
    "else:\n",
    "    wide_df = pd.DataFrame(columns=[\"cms_certification_number\"])\n",
    "\n",
    "# -------------------------- Save --------------------------------------------\n",
    "long_df.to_csv(OUT_LONG, index=False)\n",
    "wide_df.to_csv(OUT_WIDE, index=False)\n",
    "\n",
    "print(\"[save] long :\", OUT_LONG,  \" rows=\", len(long_df))\n",
    "print(\"[save] wide :\", OUT_WIDE,  \" rows=\", len(wide_df))\n",
    "\n",
    "# -------------------------- Diagnostics --------------------------------------\n",
    "all_ccns_raw = set(pd.read_csv(INPUT_FP, usecols=[\"cms_certification_number\"])[\"cms_certification_number\"]\n",
    "                     .astype(str).str.extract(r\"(\\d+)\")[0].str.zfill(6).unique())\n",
    "kept_ccns    = set(long_df[\"cms_certification_number\"].unique())\n",
    "print(\"[diagnostic] total CCNs in raw:\", len(all_ccns_raw))\n",
    "print(\"[diagnostic] CCNs after hospital filter:\", len(kept_ccns))\n",
    "print(\"[diagnostic] CCNs removed by hospital filter:\", len(all_ccns_raw - kept_ccns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b8d4d-3137-468c-88ea-b977663cf621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
