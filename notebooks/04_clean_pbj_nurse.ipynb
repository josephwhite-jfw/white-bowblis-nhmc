{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f03c866-df82-4d15-a3fe-e5e91c1ac711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths] RAW_DIR=C:\\Users\\Owner\\OneDrive\\NursingHomeData\n",
      "[paths] PBJ_DIR=C:\\Users\\Owner\\OneDrive\\NursingHomeData\\pbj-nurse\n",
      "[paths] OUT_FP=C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\pbj_monthly_panel.csv\n",
      "[scan] 33 files to process\n",
      "[read] pbj_nurse_2017_Q1.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2017_Q1.csv: 41,787 rows\n",
      "[read] pbj_nurse_2017_Q2.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2017_Q2.csv: 41,952 rows\n",
      "[read] pbj_nurse_2017_Q3.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2017_Q3.csv: 43,431 rows\n",
      "[read] pbj_nurse_2017_Q4.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2017_Q4.csv: 42,426 rows\n",
      "[read] pbj_nurse_2018_Q1.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2018_Q1.csv: 44,031 rows\n",
      "[read] pbj_nurse_2018_Q2.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2018_Q2.csv: 43,986 rows\n",
      "[read] pbj_nurse_2018_Q3.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2018_Q3.csv: 44,613 rows\n",
      "[read] pbj_nurse_2018_Q4.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2018_Q4.csv: 44,748 rows\n",
      "[read] pbj_nurse_2019_Q1.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2019_Q1.csv: 45,174 rows\n",
      "[read] pbj_nurse_2019_Q2.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2019_Q2.csv: 45,060 rows\n",
      "[read] pbj_nurse_2019_Q3.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2019_Q3.csv: 44,949 rows\n",
      "[read] pbj_nurse_2019_Q4.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2019_Q4.csv: 44,907 rows\n",
      "[read] pbj_nurse_2020_Q1.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2020_Q1.csv: 36,402 rows\n",
      "[read] pbj_nurse_2020_Q2.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2020_Q2.csv: 44,289 rows\n",
      "[read] pbj_nurse_2020_Q3.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2020_Q3.csv: 44,346 rows\n",
      "[read] pbj_nurse_2020_Q4.csv (encoding=utf-8)\n",
      "[ok] pbj_nurse_2020_Q4.csv: 44,064 rows\n",
      "[read] pbj_nurse_2021_Q1.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2021_Q1.csv: 44,571 rows\n",
      "[read] pbj_nurse_2021_Q2.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2021_Q2.csv: 44,436 rows\n",
      "[read] pbj_nurse_2021_Q3.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2021_Q3.csv: 44,418 rows\n",
      "[read] pbj_nurse_2021_Q4.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2021_Q4.csv: 43,156 rows\n",
      "[read] pbj_nurse_2022_Q1.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2022_Q1.csv: 44,256 rows\n",
      "[read] pbj_nurse_2022_Q2.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2022_Q2.csv: 44,082 rows\n",
      "[read] pbj_nurse_2022_Q3.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2022_Q3.csv: 44,064 rows\n",
      "[read] pbj_nurse_2022_Q4.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2022_Q4.csv: 44,109 rows\n",
      "[read] pbj_nurse_2023_Q1.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2023_Q1.csv: 44,097 rows\n",
      "[read] pbj_nurse_2023_Q2.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2023_Q2.csv: 43,785 rows\n",
      "[read] pbj_nurse_2023_Q3.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2023_Q3.csv: 43,833 rows\n",
      "[read] pbj_nurse_2023_Q4.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2023_Q4.csv: 43,827 rows\n",
      "[read] pbj_nurse_2024_Q1.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2024_Q1.csv: 43,878 rows\n",
      "[read] pbj_nurse_2024_Q2.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2024_Q2.csv: 43,692 rows\n",
      "[read] pbj_nurse_2024_Q3.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2024_Q3.csv: 43,644 rows\n",
      "[read] pbj_nurse_2024_Q4.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2024_Q4.csv: 43,719 rows\n",
      "[read] pbj_nurse_2025_Q1.csv (encoding=cp1252)\n",
      "[ok] pbj_nurse_2025_Q1.csv: 43,653 rows\n",
      "[done] monthly_panel rows = 1,443,385\n",
      "[saved] C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\pbj_monthly_panel.csv\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# PBJ Nurse Staffing — Build Monthly Panel\n",
    "#   * Reads all quarterly PBJ nurse CSVs (pbj_nurse_yyyy_Q*.csv)\n",
    "#   * Cleans CCNs, dates, hours, and census\n",
    "#   * Daily → monthly totals with coverage + IQR outlier filtering\n",
    "#   * Saves one combined monthly panel CSV in data/interim\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import os, warnings\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ============================== Paths / Config ================================\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "while not (PROJECT_ROOT / \"src\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "RAW_DIR  = Path(os.getenv(\"NH_DATA_DIR\", PROJECT_ROOT / \"data\" / \"raw\")).resolve()\n",
    "PBJ_DIR  = RAW_DIR / \"pbj-nurse\"\n",
    "PBJ_GLOB = \"pbj_nurse_????_Q[1-4].csv\"\n",
    "\n",
    "INTERIM_DIR = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FP = INTERIM_DIR / \"pbj_monthly_panel.csv\"\n",
    "\n",
    "print(f\"[paths] RAW_DIR={RAW_DIR}\")\n",
    "print(f\"[paths] PBJ_DIR={PBJ_DIR}\")\n",
    "print(f\"[paths] OUT_FP={OUT_FP}\")\n",
    "\n",
    "# ============================== CSV Reader ====================================\n",
    "def read_csv_robust(fp: Path) -> pd.DataFrame:\n",
    "    \"\"\"Try multiple encodings. Fall back to replace/skip if needed.\"\"\"\n",
    "    encodings = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\"]\n",
    "    last_err = None\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(fp, low_memory=False, encoding=enc, encoding_errors=\"strict\")\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    for enc in [\"cp1252\", \"latin1\"]:\n",
    "        try:\n",
    "            return pd.read_csv(fp, low_memory=False, encoding=enc,\n",
    "                               encoding_errors=\"replace\", on_bad_lines=\"skip\")\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "# ============================== Helpers =======================================\n",
    "def zero_pad_ccn(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(\"string\").str.strip().str.zfill(6)\n",
    "\n",
    "def to_date_from_int_yyyymmdd(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s.astype(\"Int64\"), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "def normalize_needed_columns(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean one PBJ quarterly file down to the columns we need.\"\"\"\n",
    "    df = df_raw.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    # rename basics\n",
    "    if \"provnum\" in df.columns and \"cms_certification_number\" not in df.columns:\n",
    "        df.rename(columns={\"provnum\": \"cms_certification_number\"}, inplace=True)\n",
    "    if \"mdscensus\" in df.columns and \"mds_census\" not in df.columns:\n",
    "        df.rename(columns={\"mdscensus\": \"mds_census\"}, inplace=True)\n",
    "\n",
    "    # add missing hour cols if absent\n",
    "    for col in [\"hrs_rn\", \"hrs_lpn\", \"hrs_cna\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    # CCN\n",
    "    if \"cms_certification_number\" in df.columns:\n",
    "        df[\"cms_certification_number\"] = zero_pad_ccn(df[\"cms_certification_number\"])\n",
    "    else:\n",
    "        warnings.warn(\"Missing cms_certification_number/provnum\")\n",
    "\n",
    "    # workdate\n",
    "    if \"workdate\" in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[\"workdate\"]) or pd.api.types.is_string_dtype(df[\"workdate\"]):\n",
    "            df[\"workdate\"] = to_date_from_int_yyyymmdd(df[\"workdate\"])\n",
    "        else:\n",
    "            df[\"workdate\"] = pd.to_datetime(df[\"workdate\"], errors=\"coerce\")\n",
    "    else:\n",
    "        raise ValueError(\"Missing workdate column\")\n",
    "\n",
    "    # hours numeric, float32\n",
    "    for c in [\"hrs_rn\", \"hrs_lpn\", \"hrs_cna\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\").fillna(0.0)\n",
    "\n",
    "    # census optional\n",
    "    if \"mds_census\" not in df.columns:\n",
    "        df[\"mds_census\"] = np.nan\n",
    "    df[\"mds_census\"] = pd.to_numeric(df[\"mds_census\"], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    keep = [\"cms_certification_number\",\"workdate\",\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"mds_census\"]\n",
    "    return df[keep]\n",
    "\n",
    "# ====================== File → Monthly Aggregation ============================\n",
    "def process_file_monthly(fp: Path,\n",
    "                         coverage_threshold: float = 0.5,\n",
    "                         iqr_mult: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build monthly totals per CCN from one file.\n",
    "    Coverage: drop months with <50% of days reported (default).\n",
    "    Outliers: drop daily values outside IQR × multiplier (default 1.5).\n",
    "    \"\"\"\n",
    "    df = normalize_needed_columns(read_csv_robust(fp))\n",
    "\n",
    "    # daily totals\n",
    "    daily = (df.groupby([\"cms_certification_number\",\"workdate\"], as_index=False)\n",
    "               .agg(hrs_rn=(\"hrs_rn\",\"sum\"),\n",
    "                    hrs_lpn=(\"hrs_lpn\",\"sum\"),\n",
    "                    hrs_cna=(\"hrs_cna\",\"sum\"),\n",
    "                    mds_census=(\"mds_census\",\"mean\")))\n",
    "    daily[\"total_hours\"] = daily[[\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\"]].sum(axis=1).astype(\"float32\")\n",
    "    daily[\"year_month\"]  = daily[\"workdate\"].dt.to_period(\"M\")\n",
    "    daily[\"days_in_month\"] = daily[\"workdate\"].dt.days_in_month\n",
    "\n",
    "    # coverage filter\n",
    "    cov = (daily.groupby([\"cms_certification_number\",\"year_month\"], as_index=False)\n",
    "                 .agg(days_reported=(\"workdate\",\"nunique\"),\n",
    "                      days_in_month=(\"days_in_month\",\"max\")))\n",
    "    cov[\"coverage_ratio\"] = cov[\"days_reported\"] / cov[\"days_in_month\"]\n",
    "    cov_ok = cov.loc[cov[\"coverage_ratio\"] >= coverage_threshold,\n",
    "                     [\"cms_certification_number\",\"year_month\",\"days_reported\"]]\n",
    "    if cov_ok.empty:\n",
    "        return pd.DataFrame(columns=[\"cms_certification_number\",\"month\",\n",
    "                                     \"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\"mds_census\",\n",
    "                                     \"hrs_rn_per_patient\",\"hrs_lpn_per_patient\",\n",
    "                                     \"hrs_cna_per_patient\",\"total_hours_per_patient\",\"n\"])\n",
    "\n",
    "    good = daily.merge(cov_ok, on=[\"cms_certification_number\",\"year_month\"], how=\"inner\")\n",
    "\n",
    "    # outlier bounds (IQR)\n",
    "    KEYS = [\"cms_certification_number\",\"year_month\"]\n",
    "    stats = (good.groupby(KEYS)\n",
    "                 .agg(rn_q1=('hrs_rn', lambda s: s.quantile(0.25)),\n",
    "                      rn_q3=('hrs_rn', lambda s: s.quantile(0.75)),\n",
    "                      lpn_q1=('hrs_lpn', lambda s: s.quantile(0.25)),\n",
    "                      lpn_q3=('hrs_lpn', lambda s: s.quantile(0.75)),\n",
    "                      cna_q1=('hrs_cna', lambda s: s.quantile(0.25)),\n",
    "                      cna_q3=('hrs_cna', lambda s: s.quantile(0.75)),\n",
    "                      tot_q1=('total_hours', lambda s: s.quantile(0.25)),\n",
    "                      tot_q3=('total_hours', lambda s: s.quantile(0.75)))\n",
    "                 .reset_index())\n",
    "    for pref in [\"rn\",\"lpn\",\"cna\",\"tot\"]:\n",
    "        q1, q3 = f\"{pref}_q1\", f\"{pref}_q3\"\n",
    "        stats[f\"{pref}_iqr\"] = stats[q3] - stats[q1]\n",
    "        stats[f\"{pref}_lo\"]  = stats[q1] - iqr_mult * stats[f\"{pref}_iqr\"]\n",
    "        stats[f\"{pref}_hi\"]  = stats[q3] + iqr_mult * stats[f\"{pref}_iqr\"]\n",
    "        z = stats[f\"{pref}_iqr\"] == 0\n",
    "        stats.loc[z, f\"{pref}_lo\"] = stats.loc[z, q1]\n",
    "        stats.loc[z, f\"{pref}_hi\"] = stats.loc[z, q3]\n",
    "\n",
    "    bounds = stats[KEYS + [f\"{p}_{b}\" for p in [\"rn\",\"lpn\",\"cna\",\"tot\"] for b in [\"lo\",\"hi\"]]]\n",
    "    good = good.merge(bounds, on=KEYS, how=\"left\")\n",
    "\n",
    "    is_outlier = (\n",
    "        (good[\"hrs_rn\"]  < good[\"rn_lo\"])  | (good[\"hrs_rn\"]  > good[\"rn_hi\"])  |\n",
    "        (good[\"hrs_lpn\"] < good[\"lpn_lo\"]) | (good[\"hrs_lpn\"] > good[\"lpn_hi\"]) |\n",
    "        (good[\"hrs_cna\"] < good[\"cna_lo\"]) | (good[\"hrs_cna\"] > good[\"cna_hi\"]) |\n",
    "        (good[\"total_hours\"] < good[\"tot_lo\"]) | (good[\"total_hours\"] > good[\"tot_hi\"])\n",
    "    )\n",
    "    kept = good.loc[~is_outlier,\n",
    "                    [\"cms_certification_number\",\"year_month\",\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\n",
    "                     \"total_hours\",\"mds_census\",\"days_reported\"]]\n",
    "\n",
    "    # monthly totals\n",
    "    monthly = (kept.groupby([\"cms_certification_number\",\"year_month\"], as_index=False)\n",
    "                    .agg(hrs_rn=(\"hrs_rn\",\"sum\"),\n",
    "                         hrs_lpn=(\"hrs_lpn\",\"sum\"),\n",
    "                         hrs_cna=(\"hrs_cna\",\"sum\"),\n",
    "                         total_hours=(\"total_hours\",\"sum\"),\n",
    "                         mds_census=(\"mds_census\",\"mean\"),\n",
    "                         n=(\"days_reported\",\"max\")))\n",
    "\n",
    "    # per-patient metrics\n",
    "    denom = monthly[\"mds_census\"].replace({0: np.nan})\n",
    "    monthly[\"hrs_rn_per_patient\"]      = monthly[\"hrs_rn\"]      / denom\n",
    "    monthly[\"hrs_lpn_per_patient\"]     = monthly[\"hrs_lpn\"]     / denom\n",
    "    monthly[\"hrs_cna_per_patient\"]     = monthly[\"hrs_cna\"]     / denom\n",
    "    monthly[\"total_hours_per_patient\"] = monthly[\"total_hours\"] / denom\n",
    "\n",
    "    # month label (MM/YYYY)\n",
    "    monthly[\"month\"] = monthly[\"year_month\"].dt.strftime(\"%m/%Y\")\n",
    "\n",
    "    # final order + dtypes\n",
    "    monthly = monthly[[\"cms_certification_number\",\"month\",\n",
    "                       \"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\"mds_census\",\n",
    "                       \"hrs_rn_per_patient\",\"hrs_lpn_per_patient\",\"hrs_cna_per_patient\",\n",
    "                       \"total_hours_per_patient\",\"n\"]]\n",
    "    for c in [\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\"mds_census\",\n",
    "              \"hrs_rn_per_patient\",\"hrs_lpn_per_patient\",\"hrs_cna_per_patient\",\"total_hours_per_patient\"]:\n",
    "        monthly[c] = monthly[c].astype(\"float32\")\n",
    "    monthly[\"n\"] = monthly[\"n\"].astype(\"Int16\")\n",
    "    return monthly\n",
    "\n",
    "# ============================== Main Runner ===================================\n",
    "def main(coverage_threshold: float = 0.5, iqr_mult: float = 1.5):\n",
    "    files = sorted(PBJ_DIR.glob(PBJ_GLOB))\n",
    "    print(f\"[scan] {len(files)} files found\")\n",
    "\n",
    "    frames = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            m = process_file_monthly(fp, coverage_threshold=coverage_threshold, iqr_mult=iqr_mult)\n",
    "            print(f\"[ok] {fp.name}: {len(m):,} rows\")\n",
    "            if not m.empty:\n",
    "                frames.append(m)\n",
    "        except Exception as e:\n",
    "            print(f\"[fail] {fp.name}: {e}\")\n",
    "\n",
    "    monthly_panel = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    print(f\"[done] monthly_panel rows = {len(monthly_panel):,}\")\n",
    "\n",
    "    monthly_panel.to_csv(OUT_FP, index=False)\n",
    "    print(f\"[saved] {OUT_FP}\")\n",
    "\n",
    "# ============================== Script Entry ==================================\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Build PBJ monthly staffing panel\")\n",
    "    parser.add_argument(\"--coverage_threshold\", type=float, default=0.5,\n",
    "                        help=\"Min days reported / days in month (default 0.5)\")\n",
    "    parser.add_argument(\"--iqr_mult\", type=float, default=1.5,\n",
    "                        help=\"Multiplier for IQR outlier filtering (default 1.5)\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(coverage_threshold=args.coverage_threshold, iqr_mult=args.iqr_mult)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
