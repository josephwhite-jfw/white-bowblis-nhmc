{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f03c866-df82-4d15-a3fe-e5e91c1ac711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths] RAW_DIR=C:\\Users\\wrthj\\OneDrive\\NursingHomeData\n",
      "[paths] PBJ_DIR=C:\\Users\\wrthj\\OneDrive\\NursingHomeData\\pbj-nurse\n",
      "[paths] OUT_FP=C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\pbj_monthly_panel.csv\n",
      "[scan] 33 files to process\n",
      "[read] pbj_nurse_2017_Q1.csv (encoding=utf-8)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 208\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m all_files:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         m = process_file_monthly(fp, coverage_threshold=\u001b[32m0.5\u001b[39m, iqr_mult=\u001b[32m1.5\u001b[39m)\n\u001b[32m    209\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[ok] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfp.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m m.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 137\u001b[39m, in \u001b[36mprocess_file_monthly\u001b[39m\u001b[34m(fp, coverage_threshold, iqr_mult)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# IQR bounds\u001b[39;00m\n\u001b[32m    135\u001b[39m KEYS = [\u001b[33m\"\u001b[39m\u001b[33mcms_certification_number\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33myear_month\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    136\u001b[39m stats = (good.groupby(KEYS)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m              .agg(rn_q1=(\u001b[33m'\u001b[39m\u001b[33mhrs_rn\u001b[39m\u001b[33m'\u001b[39m,      \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    138\u001b[39m                   rn_q3=(\u001b[33m'\u001b[39m\u001b[33mhrs_rn\u001b[39m\u001b[33m'\u001b[39m,      \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)),\n\u001b[32m    139\u001b[39m                   lpn_q1=(\u001b[33m'\u001b[39m\u001b[33mhrs_lpn\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    140\u001b[39m                   lpn_q3=(\u001b[33m'\u001b[39m\u001b[33mhrs_lpn\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)),\n\u001b[32m    141\u001b[39m                   cna_q1=(\u001b[33m'\u001b[39m\u001b[33mhrs_cna\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    142\u001b[39m                   cna_q3=(\u001b[33m'\u001b[39m\u001b[33mhrs_cna\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)),\n\u001b[32m    143\u001b[39m                   tot_q1=(\u001b[33m'\u001b[39m\u001b[33mtotal_hours\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    144\u001b[39m                   tot_q3=(\u001b[33m'\u001b[39m\u001b[33mtotal_hours\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)))\n\u001b[32m    145\u001b[39m              .reset_index())\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pref \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrn\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mlpn\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcna\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mtot\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    147\u001b[39m     q1, q3 = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpref\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_q1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpref\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_q3\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = op.agg()\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_dict_like()\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_or_apply_dict_like(op_name=\u001b[33m\"\u001b[39m\u001b[33magg\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1608\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1603\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1605\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1606\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1607\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1608\u001b[39m     result_index, result_data = \u001b[38;5;28mself\u001b[39m.compute_dict_like(\n\u001b[32m   1609\u001b[39m         op_name, selected_obj, selection, kwargs\n\u001b[32m   1610\u001b[39m     )\n\u001b[32m   1611\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:497\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m         results += key_data\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[32m    496\u001b[39m     results = [\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m         \u001b[38;5;28mgetattr\u001b[39m(obj._gotitem(key, ndim=\u001b[32m1\u001b[39m), op_name)(how, **kwargs)\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func.items()\n\u001b[32m    499\u001b[39m     ]\n\u001b[32m    500\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(func.keys())\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:257\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = engine\n\u001b[32m    256\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m ret = \u001b[38;5;28mself\u001b[39m._aggregate_multiple_funcs(func, *args, **kwargs)\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:362\u001b[39m, in \u001b[36mSeriesGroupBy._aggregate_multiple_funcs\u001b[39m\u001b[34m(self, arg, *args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[32m    361\u001b[39m         key = base.OutputKey(label=name, position=idx)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         results[key] = \u001b[38;5;28mself\u001b[39m.aggregate(func, *args, **kwargs)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results.values()):\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:291\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._constructor(\n\u001b[32m    284\u001b[39m         [],\n\u001b[32m    285\u001b[39m         name=\u001b[38;5;28mself\u001b[39m.obj.name,\n\u001b[32m    286\u001b[39m         index=\u001b[38;5;28mself\u001b[39m._grouper.result_index,\n\u001b[32m    287\u001b[39m         dtype=obj.dtype,\n\u001b[32m    288\u001b[39m     )\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grouper.nkeys > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._python_agg_general(func, *args, **kwargs)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._python_agg_general(func, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:327\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, *args, **kwargs)\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m result = \u001b[38;5;28mself\u001b[39m._grouper.agg_series(obj, f)\n\u001b[32m    328\u001b[39m res = obj._constructor(result, name=obj.name)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj._values, np.ndarray):\n\u001b[32m    858\u001b[39m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28mself\u001b[39m._aggregate_series_pure_python(obj, func)\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    882\u001b[39m splitter = \u001b[38;5;28mself\u001b[39m._get_splitter(obj, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = func(group)\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[32m    889\u001b[39m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:324\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    322\u001b[39m     alias = com._builtin_table_alias[func]\n\u001b[32m    323\u001b[39m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, *args, **kwargs)\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m    327\u001b[39m result = \u001b[38;5;28mself\u001b[39m._grouper.agg_series(obj, f)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mprocess_file_monthly.<locals>.<lambda>\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# IQR bounds\u001b[39;00m\n\u001b[32m    135\u001b[39m KEYS = [\u001b[33m\"\u001b[39m\u001b[33mcms_certification_number\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33myear_month\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    136\u001b[39m stats = (good.groupby(KEYS)\n\u001b[32m    137\u001b[39m              .agg(rn_q1=(\u001b[33m'\u001b[39m\u001b[33mhrs_rn\u001b[39m\u001b[33m'\u001b[39m,      \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    138\u001b[39m                   rn_q3=(\u001b[33m'\u001b[39m\u001b[33mhrs_rn\u001b[39m\u001b[33m'\u001b[39m,      \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)),\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m                   lpn_q1=(\u001b[33m'\u001b[39m\u001b[33mhrs_lpn\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    140\u001b[39m                   lpn_q3=(\u001b[33m'\u001b[39m\u001b[33mhrs_lpn\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)),\n\u001b[32m    141\u001b[39m                   cna_q1=(\u001b[33m'\u001b[39m\u001b[33mhrs_cna\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    142\u001b[39m                   cna_q3=(\u001b[33m'\u001b[39m\u001b[33mhrs_cna\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)),\n\u001b[32m    143\u001b[39m                   tot_q1=(\u001b[33m'\u001b[39m\u001b[33mtotal_hours\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.25\u001b[39m)),\n\u001b[32m    144\u001b[39m                   tot_q3=(\u001b[33m'\u001b[39m\u001b[33mtotal_hours\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;28;01mlambda\u001b[39;00m s: s.quantile(\u001b[32m0.75\u001b[39m)))\n\u001b[32m    145\u001b[39m              .reset_index())\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pref \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrn\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mlpn\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcna\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mtot\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    147\u001b[39m     q1, q3 = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpref\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_q1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpref\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_q3\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\series.py:2887\u001b[39m, in \u001b[36mSeries.quantile\u001b[39m\u001b[34m(self, q, interpolation)\u001b[39m\n\u001b[32m   2883\u001b[39m \u001b[38;5;66;03m# We dispatch to DataFrame so that core.internals only has to worry\u001b[39;00m\n\u001b[32m   2884\u001b[39m \u001b[38;5;66;03m#  about 2D cases.\u001b[39;00m\n\u001b[32m   2885\u001b[39m df = \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m-> \u001b[39m\u001b[32m2887\u001b[39m result = df.quantile(q=q, interpolation=interpolation, numeric_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2888\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   2889\u001b[39m     result = result.iloc[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:12146\u001b[39m, in \u001b[36mDataFrame.quantile\u001b[39m\u001b[34m(self, q, axis, numeric_only, interpolation, method)\u001b[39m\n\u001b[32m  12140\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(axis)\n\u001b[32m  12142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(q):\n\u001b[32m  12143\u001b[39m     \u001b[38;5;66;03m# BlockManager.quantile expects listlike, so we wrap and unwrap here\u001b[39;00m\n\u001b[32m  12144\u001b[39m     \u001b[38;5;66;03m# error: List item 0 has incompatible type \"float | ExtensionArray |\u001b[39;00m\n\u001b[32m  12145\u001b[39m     \u001b[38;5;66;03m# ndarray[Any, Any] | Index | Series | Sequence[float]\"; expected \"float\"\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12146\u001b[39m     res_df = \u001b[38;5;28mself\u001b[39m.quantile(\n\u001b[32m  12147\u001b[39m         [q],  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m  12148\u001b[39m         axis=axis,\n\u001b[32m  12149\u001b[39m         numeric_only=numeric_only,\n\u001b[32m  12150\u001b[39m         interpolation=interpolation,\n\u001b[32m  12151\u001b[39m         method=method,\n\u001b[32m  12152\u001b[39m     )\n\u001b[32m  12153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33msingle\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m  12154\u001b[39m         res = res_df.iloc[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:12191\u001b[39m, in \u001b[36mDataFrame.quantile\u001b[39m\u001b[34m(self, q, axis, numeric_only, interpolation, method)\u001b[39m\n\u001b[32m  12187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m  12188\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Method must be in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m  12189\u001b[39m     )\n\u001b[32m  12190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33msingle\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12191\u001b[39m     res = data._mgr.quantile(qs=q, interpolation=interpolation)\n\u001b[32m  12192\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m  12193\u001b[39m     valid_interpolation = {\u001b[33m\"\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlower\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhigher\u001b[39m\u001b[33m\"\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1549\u001b[39m, in \u001b[36mBlockManager.quantile\u001b[39m\u001b[34m(self, qs, interpolation)\u001b[39m\n\u001b[32m   1545\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m   1546\u001b[39m new_axes[\u001b[32m1\u001b[39m] = Index(qs, dtype=np.float64)\n\u001b[32m   1548\u001b[39m blocks = [\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m     blk.quantile(qs=qs, interpolation=interpolation) \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m   1550\u001b[39m ]\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1891\u001b[39m, in \u001b[36mBlock.quantile\u001b[39m\u001b[34m(self, qs, interpolation)\u001b[39m\n\u001b[32m   1888\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m\n\u001b[32m   1889\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m is_list_like(qs)  \u001b[38;5;66;03m# caller is responsible for this\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1891\u001b[39m result = quantile_compat(\u001b[38;5;28mself\u001b[39m.values, np.asarray(qs._values), interpolation)\n\u001b[32m   1892\u001b[39m \u001b[38;5;66;03m# ensure_block_shape needed for cases where we start with EA and result\u001b[39;00m\n\u001b[32m   1893\u001b[39m \u001b[38;5;66;03m#  is ndarray, e.g. IntegerArray, SparseArray\u001b[39;00m\n\u001b[32m   1894\u001b[39m result = ensure_block_shape(result, ndim=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:39\u001b[39m, in \u001b[36mquantile_compat\u001b[39m\u001b[34m(values, qs, interpolation)\u001b[39m\n\u001b[32m     37\u001b[39m     fill_value = na_value_for_dtype(values.dtype, compat=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     38\u001b[39m     mask = isna(values)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m quantile_with_mask(values, mask, fill_value, qs, interpolation)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values._quantile(qs, interpolation)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:97\u001b[39m, in \u001b[36mquantile_with_mask\u001b[39m\u001b[34m(values, mask, fill_value, qs, interpolation)\u001b[39m\n\u001b[32m     95\u001b[39m     result = np.repeat(flat, \u001b[38;5;28mlen\u001b[39m(values)).reshape(\u001b[38;5;28mlen\u001b[39m(values), \u001b[38;5;28mlen\u001b[39m(qs))\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     result = _nanpercentile(\n\u001b[32m     98\u001b[39m         values,\n\u001b[32m     99\u001b[39m         qs * \u001b[32m100.0\u001b[39m,\n\u001b[32m    100\u001b[39m         na_value=fill_value,\n\u001b[32m    101\u001b[39m         mask=mask,\n\u001b[32m    102\u001b[39m         interpolation=interpolation,\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    105\u001b[39m     result = np.asarray(result)\n\u001b[32m    106\u001b[39m     result = result.T\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:218\u001b[39m, in \u001b[36m_nanpercentile\u001b[39m\u001b[34m(values, qs, na_value, mask, interpolation)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.percentile(\n\u001b[32m    219\u001b[39m         values,\n\u001b[32m    220\u001b[39m         qs,\n\u001b[32m    221\u001b[39m         axis=\u001b[32m1\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[38;5;66;03m# error: No overload variant of \"percentile\" matches argument types\u001b[39;00m\n\u001b[32m    223\u001b[39m         \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"ndarray[Any, dtype[floating[_64Bit]]]\",\u001b[39;00m\n\u001b[32m    224\u001b[39m         \u001b[38;5;66;03m# \"int\", \"Dict[str, str]\"  [call-overload]\u001b[39;00m\n\u001b[32m    225\u001b[39m         method=interpolation,  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4273\u001b[39m, in \u001b[36mpercentile\u001b[39m\u001b[34m(a, q, axis, out, overwrite_input, method, keepdims, weights, interpolation)\u001b[39m\n\u001b[32m   4270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(weights < \u001b[32m0\u001b[39m):\n\u001b[32m   4271\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWeights must be non-negative.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[32m   4274\u001b[39m     a, q, axis, out, overwrite_input, method, keepdims, weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4550\u001b[39m, in \u001b[36m_quantile_unchecked\u001b[39m\u001b[34m(a, q, axis, out, overwrite_input, method, keepdims, weights)\u001b[39m\n\u001b[32m   4541\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_quantile_unchecked\u001b[39m(a,\n\u001b[32m   4542\u001b[39m                         q,\n\u001b[32m   4543\u001b[39m                         axis=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4547\u001b[39m                         keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   4548\u001b[39m                         weights=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   4549\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _ureduce(a,\n\u001b[32m   4551\u001b[39m                     func=_quantile_ureduce_func,\n\u001b[32m   4552\u001b[39m                     q=q,\n\u001b[32m   4553\u001b[39m                     weights=weights,\n\u001b[32m   4554\u001b[39m                     keepdims=keepdims,\n\u001b[32m   4555\u001b[39m                     axis=axis,\n\u001b[32m   4556\u001b[39m                     out=out,\n\u001b[32m   4557\u001b[39m                     overwrite_input=overwrite_input,\n\u001b[32m   4558\u001b[39m                     method=method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3894\u001b[39m, in \u001b[36m_ureduce\u001b[39m\u001b[34m(a, func, keepdims, **kwargs)\u001b[39m\n\u001b[32m   3891\u001b[39m             index_out = (\u001b[32m0\u001b[39m, ) * nd\n\u001b[32m   3892\u001b[39m             kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out[(\u001b[38;5;28mEllipsis\u001b[39m, ) + index_out]\n\u001b[32m-> \u001b[39m\u001b[32m3894\u001b[39m r = func(a, **kwargs)\n\u001b[32m   3896\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4727\u001b[39m, in \u001b[36m_quantile_ureduce_func\u001b[39m\u001b[34m(a, q, weights, axis, out, overwrite_input, method)\u001b[39m\n\u001b[32m   4725\u001b[39m         arr = a.copy()\n\u001b[32m   4726\u001b[39m         wgt = weights\n\u001b[32m-> \u001b[39m\u001b[32m4727\u001b[39m result = _quantile(arr,\n\u001b[32m   4728\u001b[39m                    quantiles=q,\n\u001b[32m   4729\u001b[39m                    axis=axis,\n\u001b[32m   4730\u001b[39m                    method=method,\n\u001b[32m   4731\u001b[39m                    out=out,\n\u001b[32m   4732\u001b[39m                    weights=wgt)\n\u001b[32m   4733\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4856\u001b[39m, in \u001b[36m_quantile\u001b[39m\u001b[34m(arr, quantiles, axis, method, out, weights)\u001b[39m\n\u001b[32m   4854\u001b[39m \u001b[38;5;28mnext\u001b[39m = arr[next_indexes]\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# --- Linear interpolation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4856\u001b[39m gamma = _get_gamma(virtual_indexes, previous_indexes, method_props)\n\u001b[32m   4857\u001b[39m result_shape = virtual_indexes.shape + (\u001b[32m1\u001b[39m,) * (arr.ndim - \u001b[32m1\u001b[39m)\n\u001b[32m   4858\u001b[39m gamma = gamma.reshape(result_shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4615\u001b[39m, in \u001b[36m_get_gamma\u001b[39m\u001b[34m(virtual_indexes, previous_indexes, method)\u001b[39m\n\u001b[32m   4591\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4592\u001b[39m \u001b[33;03m    Compute the floating point indexes of an array for the linear\u001b[39;00m\n\u001b[32m   4593\u001b[39m \u001b[33;03m    interpolation of quantiles.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4608\u001b[39m \u001b[33;03m    DOI: 10.1080/00031305.1996.10473566\u001b[39;00m\n\u001b[32m   4609\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m n * quantiles + (\n\u001b[32m   4611\u001b[39m             alpha + quantiles * (\u001b[32m1\u001b[39m - alpha - beta)\n\u001b[32m   4612\u001b[39m     ) - \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m4615\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_gamma\u001b[39m(virtual_indexes, previous_indexes, method):\n\u001b[32m   4616\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4617\u001b[39m \u001b[33;03m    Compute gamma (a.k.a 'm' or 'weight') for the linear interpolation\u001b[39;00m\n\u001b[32m   4618\u001b[39m \u001b[33;03m    of quantiles.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4630\u001b[39m \u001b[33;03m    by the interpolation method.\u001b[39;00m\n\u001b[32m   4631\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4632\u001b[39m     gamma = np.asanyarray(virtual_indexes - previous_indexes)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os, re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Paths (from your previous config) ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "while not (PROJECT_ROOT / \"src\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "RAW_DIR  = Path(os.getenv(\"NH_DATA_DIR\", PROJECT_ROOT / \"data\" / \"raw\")).resolve()\n",
    "PBJ_DIR  = RAW_DIR / \"pbj-nurse\"\n",
    "PBJ_GLOB = \"pbj_nurse_????_Q[1-4].csv\"\n",
    "\n",
    "# interim output\n",
    "INTERIM_DIR = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FP = INTERIM_DIR / \"pbj_monthly_panel.csv\"\n",
    "\n",
    "print(f\"[paths] RAW_DIR={RAW_DIR}\")\n",
    "print(f\"[paths] PBJ_DIR={PBJ_DIR}\")\n",
    "print(f\"[paths] OUT_FP={OUT_FP}\")\n",
    "\n",
    "# --- Robust CSV reader (mixed encodings happen) ---\n",
    "_TRY_ENCODINGS = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\"]\n",
    "def read_csv_robust(fp: Path) -> pd.DataFrame:\n",
    "    last_err = None\n",
    "    for enc in _TRY_ENCODINGS:\n",
    "        try:\n",
    "            df = pd.read_csv(fp, low_memory=False, encoding=enc, encoding_errors=\"strict\")\n",
    "            print(f\"[read] {fp.name} (encoding={enc})\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    for enc in [\"cp1252\",\"latin1\"]:\n",
    "        try:\n",
    "            df = pd.read_csv(fp, low_memory=False, encoding=enc, encoding_errors=\"replace\", on_bad_lines=\"skip\")\n",
    "            print(f\"[read] {fp.name} (encoding={enc}, replace+skip)\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "# --- Minimal per-file cleaner for columns we need ---\n",
    "def zero_pad_ccn(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\").str.strip()\n",
    "    s = s.where(s.ne(\"<NA>\"))\n",
    "    return s.str.zfill(6)\n",
    "\n",
    "def to_date_from_int_yyyymmdd(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s.astype(\"Int64\"), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "def normalize_needed_columns(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    # rename essentials\n",
    "    if \"provnum\" in df.columns and \"cms_certification_number\" not in df.columns:\n",
    "        df.rename(columns={\"provnum\":\"cms_certification_number\"}, inplace=True)\n",
    "    if \"mdscensus\" in df.columns and \"mds_census\" not in df.columns:\n",
    "        df.rename(columns={\"mdscensus\":\"mds_census\"}, inplace=True)\n",
    "\n",
    "    # ensure hour cols exist\n",
    "    for col in [\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    # IDs\n",
    "    if \"cms_certification_number\" in df.columns:\n",
    "        df[\"cms_certification_number\"] = zero_pad_ccn(df[\"cms_certification_number\"])\n",
    "    else:\n",
    "        warnings.warn(\"Missing cms_certification_number/provnum\")\n",
    "\n",
    "    # workdate\n",
    "    if \"workdate\" in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[\"workdate\"]) or pd.api.types.is_string_dtype(df[\"workdate\"]):\n",
    "            df[\"workdate\"] = to_date_from_int_yyyymmdd(df[\"workdate\"])\n",
    "        else:\n",
    "            df[\"workdate\"] = pd.to_datetime(df[\"workdate\"], errors=\"coerce\")\n",
    "    else:\n",
    "        raise ValueError(\"Missing workdate\")\n",
    "\n",
    "    # hours numeric, float32\n",
    "    for c in [\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\").fillna(0.0)\n",
    "\n",
    "    # census optional -> float32\n",
    "    if \"mds_census\" not in df.columns:\n",
    "        df[\"mds_census\"] = np.nan\n",
    "    df[\"mds_census\"] = pd.to_numeric(df[\"mds_census\"], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    keep = [\"cms_certification_number\",\"workdate\",\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"mds_census\"]\n",
    "    return df[keep]\n",
    "\n",
    "# --- Coverage + IQR outlier removal within facility-month, then monthly agg ---\n",
    "def process_file_monthly(fp: Path,\n",
    "                         coverage_threshold: float = 0.5,\n",
    "                         iqr_mult: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns monthly totals per CCN from a single CSV, with n = # reported days in that month (before outlier drop).\n",
    "    Adds per-patient metrics using average monthly mds_census.\n",
    "    \"\"\"\n",
    "    df = normalize_needed_columns(read_csv_robust(fp))\n",
    "\n",
    "    # daily facility-level totals\n",
    "    daily = (df\n",
    "             .groupby([\"cms_certification_number\",\"workdate\"], as_index=False)\n",
    "             .agg(hrs_rn=(\"hrs_rn\",\"sum\"),\n",
    "                  hrs_lpn=(\"hrs_lpn\",\"sum\"),\n",
    "                  hrs_cna=(\"hrs_cna\",\"sum\"),\n",
    "                  mds_census=(\"mds_census\",\"mean\"))\n",
    "            )\n",
    "    daily[\"total_hours\"] = daily[[\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\"]].sum(axis=1).astype(\"float32\")\n",
    "    daily[\"year_month\"]  = daily[\"workdate\"].dt.to_period(\"M\")\n",
    "    daily[\"days_in_month\"] = daily[\"workdate\"].dt.days_in_month\n",
    "\n",
    "    # coverage\n",
    "    cov = (daily\n",
    "           .groupby([\"cms_certification_number\",\"year_month\"], as_index=False)\n",
    "           .agg(days_reported=(\"workdate\",\"nunique\"),\n",
    "                days_in_month=(\"days_in_month\",\"max\"))\n",
    "          )\n",
    "    cov[\"coverage_ratio\"] = cov[\"days_reported\"] / cov[\"days_in_month\"]\n",
    "    cov_ok = cov.loc[cov[\"coverage_ratio\"] >= coverage_threshold,\n",
    "                     [\"cms_certification_number\",\"year_month\",\"days_reported\"]]\n",
    "    if cov_ok.empty:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"cms_certification_number\",\"month\",\n",
    "            \"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\"mds_census\",\n",
    "            \"hrs_rn_per_patient\",\"hrs_lpn_per_patient\",\"hrs_cna_per_patient\",\"total_hours_per_patient\",\"n\"\n",
    "        ])\n",
    "\n",
    "    good = daily.merge(cov_ok, on=[\"cms_certification_number\",\"year_month\"], how=\"inner\")\n",
    "\n",
    "    # IQR bounds\n",
    "    KEYS = [\"cms_certification_number\",\"year_month\"]\n",
    "    stats = (good.groupby(KEYS)\n",
    "                 .agg(rn_q1=('hrs_rn',      lambda s: s.quantile(0.25)),\n",
    "                      rn_q3=('hrs_rn',      lambda s: s.quantile(0.75)),\n",
    "                      lpn_q1=('hrs_lpn',    lambda s: s.quantile(0.25)),\n",
    "                      lpn_q3=('hrs_lpn',    lambda s: s.quantile(0.75)),\n",
    "                      cna_q1=('hrs_cna',    lambda s: s.quantile(0.25)),\n",
    "                      cna_q3=('hrs_cna',    lambda s: s.quantile(0.75)),\n",
    "                      tot_q1=('total_hours',lambda s: s.quantile(0.25)),\n",
    "                      tot_q3=('total_hours',lambda s: s.quantile(0.75)))\n",
    "                 .reset_index())\n",
    "    for pref in [\"rn\",\"lpn\",\"cna\",\"tot\"]:\n",
    "        q1, q3 = f\"{pref}_q1\", f\"{pref}_q3\"\n",
    "        stats[f\"{pref}_iqr\"] = (stats[q3] - stats[q1])\n",
    "        stats[f\"{pref}_lo\"]  = stats[q1] - iqr_mult * stats[f\"{pref}_iqr\"]\n",
    "        stats[f\"{pref}_hi\"]  = stats[q3] + iqr_mult * stats[f\"{pref}_iqr\"]\n",
    "        z = stats[f\"{pref}_iqr\"] == 0\n",
    "        stats.loc[z, f\"{pref}_lo\"] = stats.loc[z, q1]\n",
    "        stats.loc[z, f\"{pref}_hi\"] = stats.loc[z, q3]\n",
    "\n",
    "    bounds = stats[KEYS + [f\"{p}_{b}\" for p in [\"rn\",\"lpn\",\"cna\",\"tot\"] for b in [\"lo\",\"hi\"]]]\n",
    "    good = good.merge(bounds, on=KEYS, how=\"left\")\n",
    "\n",
    "    is_outlier = (\n",
    "        (good[\"hrs_rn\"]  < good[\"rn_lo\"])  | (good[\"hrs_rn\"]  > good[\"rn_hi\"])  |\n",
    "        (good[\"hrs_lpn\"] < good[\"lpn_lo\"]) | (good[\"hrs_lpn\"] > good[\"lpn_hi\"]) |\n",
    "        (good[\"hrs_cna\"] < good[\"cna_lo\"]) | (good[\"hrs_cna\"] > good[\"cna_hi\"]) |\n",
    "        (good[\"total_hours\"] < good[\"tot_lo\"]) | (good[\"total_hours\"] > good[\"tot_hi\"])\n",
    "    )\n",
    "    kept = good.loc[~is_outlier,\n",
    "                    [\"cms_certification_number\",\"year_month\",\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\"mds_census\",\"days_reported\"]]\n",
    "\n",
    "    # monthly totals and avg census (across reported days kept)\n",
    "    monthly = (kept\n",
    "               .groupby([\"cms_certification_number\",\"year_month\"], as_index=False)\n",
    "               .agg(hrs_rn=(\"hrs_rn\",\"sum\"),\n",
    "                    hrs_lpn=(\"hrs_lpn\",\"sum\"),\n",
    "                    hrs_cna=(\"hrs_cna\",\"sum\"),\n",
    "                    total_hours=(\"total_hours\",\"sum\"),\n",
    "                    mds_census=(\"mds_census\",\"mean\"),\n",
    "                    n=(\"days_reported\",\"max\"))\n",
    "              )\n",
    "\n",
    "    # per-patient metrics\n",
    "    denom = monthly[\"mds_census\"].replace({0: np.nan})\n",
    "    monthly[\"hrs_rn_per_patient\"]     = monthly[\"hrs_rn\"]     / denom\n",
    "    monthly[\"hrs_lpn_per_patient\"]    = monthly[\"hrs_lpn\"]    / denom\n",
    "    monthly[\"hrs_cna_per_patient\"]    = monthly[\"hrs_cna\"]    / denom\n",
    "    monthly[\"total_hours_per_patient\"]= monthly[\"total_hours\"]/ denom\n",
    "\n",
    "    # Month label like 01/2017\n",
    "    monthly[\"month\"] = monthly[\"year_month\"].dt.strftime(\"%m/%Y\")\n",
    "\n",
    "    # Final column order + dtypes\n",
    "    monthly = monthly[[\n",
    "        \"cms_certification_number\",\"month\",\n",
    "        \"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\"mds_census\",\n",
    "        \"hrs_rn_per_patient\",\"hrs_lpn_per_patient\",\"hrs_cna_per_patient\",\"total_hours_per_patient\",\"n\"\n",
    "    ]]\n",
    "    for c in [\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\n",
    "              \"mds_census\",\"hrs_rn_per_patient\",\"hrs_lpn_per_patient\",\n",
    "              \"hrs_cna_per_patient\",\"total_hours_per_patient\"]:\n",
    "        monthly[c] = monthly[c].astype(\"float32\")\n",
    "    monthly[\"n\"] = monthly[\"n\"].astype(\"Int16\")\n",
    "    return monthly\n",
    "\n",
    "# --- Run file-by-file and concatenate ---\n",
    "all_files = sorted(PBJ_DIR.glob(PBJ_GLOB))\n",
    "print(f\"[scan] {len(all_files)} files to process\")\n",
    "\n",
    "monthly_frames = []\n",
    "for fp in all_files:\n",
    "    try:\n",
    "        m = process_file_monthly(fp, coverage_threshold=0.5, iqr_mult=1.5)\n",
    "        print(f\"[ok] {fp.name}: {len(m):,} rows\")\n",
    "        if not m.empty:\n",
    "            monthly_frames.append(m)\n",
    "    except Exception as e:\n",
    "        print(f\"[fail] {fp.name}: {e}\")\n",
    "\n",
    "monthly_panel = (\n",
    "    pd.concat(monthly_frames, ignore_index=True)\n",
    "    if monthly_frames else\n",
    "    pd.DataFrame(columns=[\n",
    "        \"cms_certification_number\",\"month\",\n",
    "        \"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\",\"mds_census\",\n",
    "        \"hrs_rn_per_patient\",\"hrs_lpn_per_patient\",\"hrs_cna_per_patient\",\"total_hours_per_patient\",\"n\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(f\"[done] monthly_panel rows = {len(monthly_panel):,}\")\n",
    "\n",
    "# --- Save to interim ---\n",
    "monthly_panel.to_csv(OUT_FP, index=False)\n",
    "print(f\"[saved] {OUT_FP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b502f-7872-4090-b528-2f3b2343ad51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
