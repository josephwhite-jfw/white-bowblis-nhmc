{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64260ef9-e7c7-4f00-889b-ef444dc52be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633ff0f7-c965-4da0-89a0-06aae764f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_24916\\4143783690.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\Owner\\OneDrive\\NursingHomeData\\pbj-nurse\\pbj_nurse_2017_Q1.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Owner\\OneDrive\\NursingHomeData\\pbj-nurse\\pbj_nurse_2017_Q1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c95423-d61b-4bd3-b397-a11174e0e9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  provnum                  provname          city state county_name  \\\n",
      "0   15009  BURNS NURSING HOME, INC.  RUSSELLVILLE    AL    Franklin   \n",
      "1   15009  BURNS NURSING HOME, INC.  RUSSELLVILLE    AL    Franklin   \n",
      "2   15009  BURNS NURSING HOME, INC.  RUSSELLVILLE    AL    Franklin   \n",
      "3   15009  BURNS NURSING HOME, INC.  RUSSELLVILLE    AL    Franklin   \n",
      "4   15009  BURNS NURSING HOME, INC.  RUSSELLVILLE    AL    Franklin   \n",
      "\n",
      "   county_fips  cy_qtr  workdate  mdscensus  hrs_rn_donadmin  ...  \\\n",
      "0           59  2017Q1  20170101         55              0.0  ...   \n",
      "1           59  2017Q1  20170102         54              0.0  ...   \n",
      "2           59  2017Q1  20170103         55              0.0  ...   \n",
      "3           59  2017Q1  20170104         55              0.0  ...   \n",
      "4           59  2017Q1  20170105         56              0.0  ...   \n",
      "\n",
      "   hrs_lpn_ctr  hrs_cna  hrs_cna_emp  hrs_cna_ctr  hrs_na_trn  hrs_natrn_emp  \\\n",
      "0          0.0   121.00       121.00          0.0         0.0            0.0   \n",
      "1          0.0   166.05       166.05          0.0         0.0            0.0   \n",
      "2          0.0   174.90       174.90          0.0         0.0            0.0   \n",
      "3          0.0   175.69       175.69          0.0         0.0            0.0   \n",
      "4          0.0   174.00       174.00          0.0         0.0            0.0   \n",
      "\n",
      "   hrs_natrn_ctr  hrs_medaide  hrs_medaide_emp  hrs_medaide_ctr  \n",
      "0            0.0          0.0              0.0              0.0  \n",
      "1            0.0          0.0              0.0              0.0  \n",
      "2            0.0          0.0              0.0              0.0  \n",
      "3            0.0          0.0              0.0              0.0  \n",
      "4            0.0          0.0              0.0              0.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "provnum\n",
      "provname\n",
      "city\n",
      "state\n",
      "county_name\n",
      "county_fips\n",
      "cy_qtr\n",
      "workdate\n",
      "mdscensus\n",
      "hrs_rn_donadmin\n",
      "hrs_rndon_emp\n",
      "hrs_rndon_ctr\n",
      "hrs_rnadmin\n",
      "hrs_rnadmin_emp\n",
      "hrs_rnadmin_ctr\n",
      "hrs_rn\n",
      "hrs_rn_emp\n",
      "hrs_rn_ctr\n",
      "hrs_lpn_admin\n",
      "hrs_lpnadmin_emp\n",
      "hrs_lpnadmin_ctr\n",
      "hrs_lpn\n",
      "hrs_lpn_emp\n",
      "hrs_lpn_ctr\n",
      "hrs_cna\n",
      "hrs_cna_emp\n",
      "hrs_cna_ctr\n",
      "hrs_na_trn\n",
      "hrs_natrn_emp\n",
      "hrs_natrn_ctr\n",
      "hrs_medaide\n",
      "hrs_medaide_emp\n",
      "hrs_medaide_ctr\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1253610 entries, 0 to 1253609\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   provnum           1253610 non-null  object \n",
      " 1   provname          1253610 non-null  object \n",
      " 2   city              1253610 non-null  object \n",
      " 3   state             1253610 non-null  object \n",
      " 4   county_name       1253610 non-null  object \n",
      " 5   county_fips       1253610 non-null  int64  \n",
      " 6   cy_qtr            1253610 non-null  object \n",
      " 7   workdate          1253610 non-null  int64  \n",
      " 8   mdscensus         1253610 non-null  int64  \n",
      " 9   hrs_rn_donadmin   1253610 non-null  float64\n",
      " 10  hrs_rndon_emp     1253610 non-null  float64\n",
      " 11  hrs_rndon_ctr     1253610 non-null  float64\n",
      " 12  hrs_rnadmin       1253610 non-null  float64\n",
      " 13  hrs_rnadmin_emp   1253610 non-null  float64\n",
      " 14  hrs_rnadmin_ctr   1253610 non-null  float64\n",
      " 15  hrs_rn            1253610 non-null  float64\n",
      " 16  hrs_rn_emp        1253610 non-null  float64\n",
      " 17  hrs_rn_ctr        1253610 non-null  float64\n",
      " 18  hrs_lpn_admin     1253610 non-null  float64\n",
      " 19  hrs_lpnadmin_emp  1253610 non-null  float64\n",
      " 20  hrs_lpnadmin_ctr  1253610 non-null  float64\n",
      " 21  hrs_lpn           1253610 non-null  float64\n",
      " 22  hrs_lpn_emp       1253610 non-null  float64\n",
      " 23  hrs_lpn_ctr       1253610 non-null  float64\n",
      " 24  hrs_cna           1253610 non-null  float64\n",
      " 25  hrs_cna_emp       1253610 non-null  float64\n",
      " 26  hrs_cna_ctr       1253610 non-null  float64\n",
      " 27  hrs_na_trn        1253610 non-null  float64\n",
      " 28  hrs_natrn_emp     1253610 non-null  float64\n",
      " 29  hrs_natrn_ctr     1253610 non-null  float64\n",
      " 30  hrs_medaide       1253610 non-null  float64\n",
      " 31  hrs_medaide_emp   1253610 non-null  float64\n",
      " 32  hrs_medaide_ctr   1253610 non-null  float64\n",
      "dtypes: float64(24), int64(3), object(6)\n",
      "memory usage: 315.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4238916d-1079-4c8b-9de3-fa09e41dd248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths] RAW_DIR=C:\\Users\\Owner\\OneDrive\\NursingHomeData\n",
      "[paths] PBJ_DIR=C:\\Users\\Owner\\OneDrive\\NursingHomeData\\pbj-nurse\n",
      "[scan] found 30 files under C:\\Users\\Owner\\OneDrive\\NursingHomeData\\pbj-nurse\n",
      "  • pbj_nurse_2017_Q1.csv\n",
      "  • pbj_nurse_2017_Q2.csv\n",
      "  • pbj_nurse_2017_Q3.csv\n",
      "  • pbj_nurse_2017_Q4.csv\n",
      "  • pbj_nurse_2018_Q1.csv\n",
      "[read] pbj_nurse_2017_Q1.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2017_Q2.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2017_Q3.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2017_Q4.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2018_Q1.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2018_Q2.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2018_Q3.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2018_Q4.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2019_Q1.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2019_Q2.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2019_Q3.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2019_Q4.csv  (encoding=utf-8)\n",
      "[read] pbj_nurse_2020_Q1.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2021_Q1.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2021_Q2.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2021_Q3.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2021_Q4.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2022_Q1.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2022_Q2.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2022_Q3.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2022_Q4.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2023_Q1.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2023_Q2.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2023_Q3.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2023_Q4.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2024_Q1.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2024_Q2.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2024_Q3.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2024_Q4.csv  (encoding=cp1252)\n",
      "[read] pbj_nurse_2025_Q1.csv  (encoding=cp1252)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cms_certification_number</th>\n",
       "      <th>provider_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>cy_qtr</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>workdate</th>\n",
       "      <th>...</th>\n",
       "      <th>hrs_na_trn_emp</th>\n",
       "      <th>hrs_na_trn_ctr</th>\n",
       "      <th>hrs_medaide</th>\n",
       "      <th>hrs_medaide_emp</th>\n",
       "      <th>hrs_medaide_ctr</th>\n",
       "      <th>source_file</th>\n",
       "      <th>hrs_rndon</th>\n",
       "      <th>hrs_lpnadmin</th>\n",
       "      <th>hrs_natrn</th>\n",
       "      <th>incomplete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>015009</td>\n",
       "      <td>BURNS NURSING HOME, INC.</td>\n",
       "      <td>Russellville</td>\n",
       "      <td>AL</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>59</td>\n",
       "      <td>2017Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pbj_nurse_2017_Q1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>015009</td>\n",
       "      <td>BURNS NURSING HOME, INC.</td>\n",
       "      <td>Russellville</td>\n",
       "      <td>AL</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>59</td>\n",
       "      <td>2017Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pbj_nurse_2017_Q1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015009</td>\n",
       "      <td>BURNS NURSING HOME, INC.</td>\n",
       "      <td>Russellville</td>\n",
       "      <td>AL</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>59</td>\n",
       "      <td>2017Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pbj_nurse_2017_Q1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>015009</td>\n",
       "      <td>BURNS NURSING HOME, INC.</td>\n",
       "      <td>Russellville</td>\n",
       "      <td>AL</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>59</td>\n",
       "      <td>2017Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pbj_nurse_2017_Q1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>015009</td>\n",
       "      <td>BURNS NURSING HOME, INC.</td>\n",
       "      <td>Russellville</td>\n",
       "      <td>AL</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>59</td>\n",
       "      <td>2017Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pbj_nurse_2017_Q1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cms_certification_number             provider_name          city state  \\\n",
       "0                   015009  BURNS NURSING HOME, INC.  Russellville    AL   \n",
       "1                   015009  BURNS NURSING HOME, INC.  Russellville    AL   \n",
       "2                   015009  BURNS NURSING HOME, INC.  Russellville    AL   \n",
       "3                   015009  BURNS NURSING HOME, INC.  Russellville    AL   \n",
       "4                   015009  BURNS NURSING HOME, INC.  Russellville    AL   \n",
       "\n",
       "  county_name  county_fips  cy_qtr  year  quarter   workdate  ...  \\\n",
       "0    Franklin           59  2017Q1  2017        1 2017-01-01  ...   \n",
       "1    Franklin           59  2017Q1  2017        1 2017-01-02  ...   \n",
       "2    Franklin           59  2017Q1  2017        1 2017-01-03  ...   \n",
       "3    Franklin           59  2017Q1  2017        1 2017-01-04  ...   \n",
       "4    Franklin           59  2017Q1  2017        1 2017-01-05  ...   \n",
       "\n",
       "   hrs_na_trn_emp  hrs_na_trn_ctr  hrs_medaide  hrs_medaide_emp  \\\n",
       "0             0.0             0.0          0.0              0.0   \n",
       "1             0.0             0.0          0.0              0.0   \n",
       "2             0.0             0.0          0.0              0.0   \n",
       "3             0.0             0.0          0.0              0.0   \n",
       "4             0.0             0.0          0.0              0.0   \n",
       "\n",
       "   hrs_medaide_ctr            source_file  hrs_rndon  hrs_lpnadmin  hrs_natrn  \\\n",
       "0              0.0  pbj_nurse_2017_Q1.csv        NaN           NaN        NaN   \n",
       "1              0.0  pbj_nurse_2017_Q1.csv        NaN           NaN        NaN   \n",
       "2              0.0  pbj_nurse_2017_Q1.csv        NaN           NaN        NaN   \n",
       "3              0.0  pbj_nurse_2017_Q1.csv        NaN           NaN        NaN   \n",
       "4              0.0  pbj_nurse_2017_Q1.csv        NaN           NaN        NaN   \n",
       "\n",
       "   incomplete  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PBJ nurse cleaner — standardize names & dtypes (reads from pbj-nurse/, no saving)\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, re, warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ── Paths ────────────────────────────────────────────────────────────────────\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "while not (PROJECT_ROOT / \"src\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "RAW_DIR  = Path(os.getenv(\"NH_DATA_DIR\", PROJECT_ROOT / \"data\" / \"raw\")).resolve()\n",
    "PBJ_DIR  = RAW_DIR / \"pbj-nurse\"   # <<— your folder\n",
    "PBJ_GLOB = \"pbj_nurse_????_Q[1-4].csv\"\n",
    "FILENAME_RE = re.compile(r\"pbj_nurse_(\\d{4})_Q([1-4])\\.csv$\", re.IGNORECASE)\n",
    "\n",
    "print(f\"[paths] RAW_DIR={RAW_DIR}\")\n",
    "print(f\"[paths] PBJ_DIR={PBJ_DIR}\")\n",
    "\n",
    "# ── Config: renames / schema ─────────────────────────────────────────────────\n",
    "RENAME_MAP = {\n",
    "    \"provnum\":          \"cms_certification_number\",\n",
    "    \"provname\":         \"provider_name\",\n",
    "    \"city\":             \"city\",\n",
    "    \"state\":            \"state\",\n",
    "    \"county_name\":      \"county_name\",\n",
    "    \"county_fips\":      \"county_fips\",\n",
    "    \"cy_qtr\":           \"cy_qtr\",\n",
    "    \"workdate\":         \"workdate\",\n",
    "    \"mdscensus\":        \"mds_census\",\n",
    "    \"hrs_rn_donadmin\":  \"hrs_rn_don_admin\",\n",
    "    \"hrs_rndon_emp\":    \"hrs_rn_don_emp\",\n",
    "    \"hrs_rndon_ctr\":    \"hrs_rn_don_ctr\",\n",
    "    \"hrs_rnadmin\":      \"hrs_rn_admin\",\n",
    "    \"hrs_rnadmin_emp\":  \"hrs_rn_admin_emp\",\n",
    "    \"hrs_rnadmin_ctr\":  \"hrs_rn_admin_ctr\",\n",
    "    \"hrs_rn\":           \"hrs_rn\",\n",
    "    \"hrs_rn_emp\":       \"hrs_rn_emp\",\n",
    "    \"hrs_rn_ctr\":       \"hrs_rn_ctr\",\n",
    "    \"hrs_lpn_admin\":    \"hrs_lpn_admin\",\n",
    "    \"hrs_lpnadmin_emp\": \"hrs_lpn_admin_emp\",\n",
    "    \"hrs_lpnadmin_ctr\": \"hrs_lpn_admin_ctr\",\n",
    "    \"hrs_lpn\":          \"hrs_lpn\",\n",
    "    \"hrs_lpn_emp\":      \"hrs_lpn_emp\",\n",
    "    \"hrs_lpn_ctr\":      \"hrs_lpn_ctr\",\n",
    "    \"hrs_cna\":          \"hrs_cna\",\n",
    "    \"hrs_cna_emp\":      \"hrs_cna_emp\",\n",
    "    \"hrs_cna_ctr\":      \"hrs_cna_ctr\",\n",
    "    \"hrs_na_trn\":       \"hrs_na_trn\",\n",
    "    \"hrs_natrn_emp\":    \"hrs_na_trn_emp\",\n",
    "    \"hrs_natrn_ctr\":    \"hrs_na_trn_ctr\",\n",
    "    \"hrs_medaide\":      \"hrs_medaide\",\n",
    "    \"hrs_medaide_emp\":  \"hrs_medaide_emp\",\n",
    "    \"hrs_medaide_ctr\":  \"hrs_medaide_ctr\",\n",
    "}\n",
    "\n",
    "HOUR_COLS = [\n",
    "    \"hrs_rn_don_admin\",\"hrs_rn_don_emp\",\"hrs_rn_don_ctr\",\n",
    "    \"hrs_rn_admin\",\"hrs_rn_admin_emp\",\"hrs_rn_admin_ctr\",\n",
    "    \"hrs_rn\",\"hrs_rn_emp\",\"hrs_rn_ctr\",\n",
    "    \"hrs_lpn_admin\",\"hrs_lpn_admin_emp\",\"hrs_lpn_admin_ctr\",\n",
    "    \"hrs_lpn\",\"hrs_lpn_emp\",\"hrs_lpn_ctr\",\n",
    "    \"hrs_cna\",\"hrs_cna_emp\",\"hrs_cna_ctr\",\n",
    "    \"hrs_na_trn\",\"hrs_na_trn_emp\",\"hrs_na_trn_ctr\",\n",
    "    \"hrs_medaide\",\"hrs_medaide_emp\",\"hrs_medaide_ctr\",\n",
    "]\n",
    "\n",
    "CANON_ORDER = [\n",
    "    \"cms_certification_number\",\"provider_name\",\"city\",\"state\",\"county_name\",\"county_fips\",\n",
    "    \"cy_qtr\",\"year\",\"quarter\",\"workdate\",\"mds_census\",\n",
    "    *HOUR_COLS,\n",
    "    \"source_file\"\n",
    "]\n",
    "\n",
    "# ── Helpers ──────────────────────────────────────────────────────────────────\n",
    "def _parse_filename_quarter(fp: Path) -> Tuple[int, int]:\n",
    "    m = FILENAME_RE.search(fp.name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Filename does not match pattern YYYY_Qn: {fp.name}\")\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def _to_datetime_from_yyyymmdd_int(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s.astype(\"Int64\"), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "def _zp6(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\").str.strip()\n",
    "    s = s.where(s.ne(\"<NA>\"))\n",
    "    return s.str.zfill(6)\n",
    "\n",
    "def _clean_one(df_raw: pd.DataFrame, src: Path) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    for old, new in RENAME_MAP.items():\n",
    "        if old in df.columns:\n",
    "            df.rename(columns={old: new}, inplace=True)\n",
    "\n",
    "    # Ensure hour columns exist\n",
    "    for c in HOUR_COLS:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "\n",
    "    # ID key\n",
    "    if \"cms_certification_number\" not in df.columns and \"provnum\" in df.columns:\n",
    "        df.rename(columns={\"provnum\":\"cms_certification_number\"}, inplace=True)\n",
    "    if \"cms_certification_number\" in df.columns:\n",
    "        df[\"cms_certification_number\"] = _zp6(df[\"cms_certification_number\"])\n",
    "    else:\n",
    "        warnings.warn(f\"{src.name}: missing cms_certification_number/provnum\")\n",
    "\n",
    "    # Strings & casing\n",
    "    for col in [\"provider_name\",\"city\",\"state\",\"county_name\",\"cy_qtr\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(\"string\").str.strip()\n",
    "    if \"state\" in df.columns: df[\"state\"] = df[\"state\"].str.upper()\n",
    "    if \"city\" in df.columns: df[\"city\"] = df[\"city\"].str.title()\n",
    "    if \"county_name\" in df.columns: df[\"county_name\"] = df[\"county_name\"].str.title()\n",
    "\n",
    "    # county_fips\n",
    "    if \"county_fips\" in df.columns:\n",
    "        df[\"county_fips\"] = pd.to_numeric(df[\"county_fips\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # workdate\n",
    "    if \"workdate\" in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[\"workdate\"]) or pd.api.types.is_string_dtype(df[\"workdate\"]):\n",
    "            df[\"workdate\"] = _to_datetime_from_yyyymmdd_int(df[\"workdate\"])\n",
    "        else:\n",
    "            df[\"workdate\"] = pd.to_datetime(df[\"workdate\"], errors=\"coerce\")\n",
    "\n",
    "    # mds_census\n",
    "    for c in [\"mds_census\",\"mdscensus\"]:\n",
    "        if c in df.columns:\n",
    "            df[\"mds_census\"] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int32\")\n",
    "            if c != \"mds_census\":\n",
    "                df.drop(columns=[c], inplace=True)\n",
    "\n",
    "    # hours -> float32\n",
    "    for c in HOUR_COLS:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\").fillna(0.0)\n",
    "\n",
    "    # year/quarter from filename; check cy_qtr\n",
    "    file_year, file_q = _parse_filename_quarter(src)\n",
    "    df[\"year\"] = file_year\n",
    "    df[\"quarter\"] = file_q\n",
    "\n",
    "    if \"cy_qtr\" in df.columns and df[\"cy_qtr\"].notna().any():\n",
    "        df[\"cy_qtr\"] = df[\"cy_qtr\"].str.upper().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "        sample = df[\"cy_qtr\"].dropna().astype(str).head(1)\n",
    "        if not sample.empty:\n",
    "            expected = f\"{file_year}Q{file_q}\"\n",
    "            if sample.iloc[0] != expected:\n",
    "                warnings.warn(f\"{src.name}: filename quarter={expected} != cy_qtr sample={sample.iloc[0]}\")\n",
    "    else:\n",
    "        df[\"cy_qtr\"] = pd.Series([f\"{file_year}Q{file_q}\"]*len(df), dtype=\"string\")\n",
    "\n",
    "    df[\"source_file\"] = src.name\n",
    "\n",
    "    # Reorder; keep extras at end\n",
    "    for col in CANON_ORDER:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "    extras = [c for c in df.columns if c not in CANON_ORDER]\n",
    "    df = df[CANON_ORDER + extras]\n",
    "    return df\n",
    "\n",
    "# --- Add these helpers above load_and_clean_pbj ---\n",
    "import pandas as pd\n",
    "\n",
    "_TRY_ENCODINGS = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\"]\n",
    "\n",
    "def _read_csv_robust(fp: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Try a few common encodings; fall back to cp1252/latin1 if needed.\n",
    "    Also tolerates a few bad lines without crashing.\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for enc in _TRY_ENCODINGS:\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                fp,\n",
    "                low_memory=False,\n",
    "                encoding=enc,\n",
    "                encoding_errors=\"strict\",   # raise first so we can try the next encoding\n",
    "                on_bad_lines=\"error\",       # raise first so we can try fallback below\n",
    "            )\n",
    "            # If that worked, we're done.\n",
    "            print(f\"[read] {fp.name}  (encoding={enc})\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "\n",
    "    # Final fallback: allow replacement + skip bad lines if any remain problematic\n",
    "    for enc in [\"cp1252\", \"latin1\"]:\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                fp,\n",
    "                low_memory=False,\n",
    "                encoding=enc,\n",
    "                encoding_errors=\"replace\",  # replace undecodable bytes\n",
    "                on_bad_lines=\"skip\",        # skip malformed rows (rare)\n",
    "            )\n",
    "            print(f\"[read] {fp.name}  (encoding={enc}, replace+skip)\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "\n",
    "    raise last_err\n",
    "\n",
    "def load_and_clean_pbj(return_concat: bool = True):\n",
    "    files = sorted(PBJ_DIR.glob(PBJ_GLOB))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files matched {PBJ_DIR / PBJ_GLOB}\")\n",
    "    print(f\"[scan] found {len(files)} files under {PBJ_DIR}\")\n",
    "    for f in files[:5]:\n",
    "        print(\"  •\", f.name)\n",
    "\n",
    "    cleaned: Dict[str, pd.DataFrame] = {}\n",
    "    for fp in files:\n",
    "        df_raw = _read_csv_robust(fp)          # <-- use robust reader\n",
    "        df = _clean_one(df_raw, fp)\n",
    "        cleaned[fp.name] = df\n",
    "\n",
    "    panel = pd.concat(cleaned.values(), axis=0, ignore_index=True) if return_concat else None\n",
    "    return cleaned, panel\n",
    "\n",
    "# ---- Example usage (uncomment to run) ----\n",
    "cleaned_map, panel_df = load_and_clean_pbj(return_concat=True)\n",
    "# • cleaned_map: dict mapping {filename -> cleaned DataFrame}\n",
    "# • panel_df   : single long DataFrame (not saved)\n",
    "panel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e3a712f-303e-4c22-9ebf-6c57603a6138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39867242 entries, 0 to 39867241\n",
      "Data columns (total 40 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   cms_certification_number  string        \n",
      " 1   provider_name             string        \n",
      " 2   city                      string        \n",
      " 3   state                     string        \n",
      " 4   county_name               string        \n",
      " 5   county_fips               Int64         \n",
      " 6   cy_qtr                    string        \n",
      " 7   year                      int64         \n",
      " 8   quarter                   int64         \n",
      " 9   workdate                  datetime64[ns]\n",
      " 10  mds_census                Int32         \n",
      " 11  hrs_rn_don_admin          float32       \n",
      " 12  hrs_rn_don_emp            float32       \n",
      " 13  hrs_rn_don_ctr            float32       \n",
      " 14  hrs_rn_admin              float32       \n",
      " 15  hrs_rn_admin_emp          float32       \n",
      " 16  hrs_rn_admin_ctr          float32       \n",
      " 17  hrs_rn                    float32       \n",
      " 18  hrs_rn_emp                float32       \n",
      " 19  hrs_rn_ctr                float32       \n",
      " 20  hrs_lpn_admin             float32       \n",
      " 21  hrs_lpn_admin_emp         float32       \n",
      " 22  hrs_lpn_admin_ctr         float32       \n",
      " 23  hrs_lpn                   float32       \n",
      " 24  hrs_lpn_emp               float32       \n",
      " 25  hrs_lpn_ctr               float32       \n",
      " 26  hrs_cna                   float32       \n",
      " 27  hrs_cna_emp               float32       \n",
      " 28  hrs_cna_ctr               float32       \n",
      " 29  hrs_na_trn                float32       \n",
      " 30  hrs_na_trn_emp            float32       \n",
      " 31  hrs_na_trn_ctr            float32       \n",
      " 32  hrs_medaide               float32       \n",
      " 33  hrs_medaide_emp           float32       \n",
      " 34  hrs_medaide_ctr           float32       \n",
      " 35  source_file               object        \n",
      " 36  hrs_rndon                 float64       \n",
      " 37  hrs_lpnadmin              float64       \n",
      " 38  hrs_natrn                 float64       \n",
      " 39  incomplete                float64       \n",
      "dtypes: Int32(1), Int64(1), datetime64[ns](1), float32(24), float64(4), int64(2), object(1), string(6)\n",
      "memory usage: 8.2+ GB\n"
     ]
    }
   ],
   "source": [
    "panel_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a18e3ea-e736-4bf6-8353-bfd2fd8c98e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       county_fips          year       quarter                       workdate  \\\n",
      "count   39867150.0  3.986724e+07  3.986724e+07                       39867242   \n",
      "mean     90.933138  2.020709e+03  2.417612e+00  2021-03-09 05:26:12.494692864   \n",
      "min            1.0  2.017000e+03  1.000000e+00            2017-01-01 00:00:00   \n",
      "25%           31.0  2.018000e+03  1.000000e+00            2018-11-22 00:00:00   \n",
      "50%           69.0  2.021000e+03  2.000000e+00            2021-07-08 00:00:00   \n",
      "75%          117.0  2.023000e+03  3.000000e+00            2023-05-18 00:00:00   \n",
      "max          840.0  2.025000e+03  4.000000e+00            2025-03-31 00:00:00   \n",
      "std      98.886944  2.486311e+00  1.140505e+00                            NaN   \n",
      "\n",
      "       mds_census  hrs_rn_don_admin  hrs_rn_don_emp  hrs_rn_don_ctr  \\\n",
      "count  39867242.0      3.986724e+07    3.986724e+07    3.986724e+07   \n",
      "mean    82.932671      2.454517e-01    4.969958e+00    8.782741e-02   \n",
      "min           0.0      0.000000e+00    0.000000e+00    0.000000e+00   \n",
      "25%          50.0      0.000000e+00    0.000000e+00    0.000000e+00   \n",
      "50%          75.0      0.000000e+00    8.000000e+00    0.000000e+00   \n",
      "75%         104.0      0.000000e+00    8.000000e+00    0.000000e+00   \n",
      "max         795.0      4.023000e+02    6.414800e+02    8.417000e+01   \n",
      "std     50.218786      2.221835e+00    3.991268e+00    8.819560e-01   \n",
      "\n",
      "       hrs_rn_admin  hrs_rn_admin_emp  ...    hrs_na_trn  hrs_na_trn_emp  \\\n",
      "count  3.986724e+07      3.986724e+07  ...  3.986724e+07    3.986724e+07   \n",
      "mean   1.093115e+01      1.070166e+01  ...  3.418951e-01    4.093740e+00   \n",
      "min    0.000000e+00      0.000000e+00  ...  0.000000e+00    0.000000e+00   \n",
      "25%    0.000000e+00      0.000000e+00  ...  0.000000e+00    0.000000e+00   \n",
      "50%    7.750000e+00      7.500000e+00  ...  0.000000e+00    0.000000e+00   \n",
      "75%    1.600000e+01      1.600000e+01  ...  0.000000e+00    0.000000e+00   \n",
      "max    1.143200e+03      8.990000e+02  ...  7.388100e+02    7.388100e+02   \n",
      "std    1.446266e+01      1.423190e+01  ...  3.773951e+00    1.215134e+01   \n",
      "\n",
      "       hrs_na_trn_ctr   hrs_medaide  hrs_medaide_emp  hrs_medaide_ctr  \\\n",
      "count    3.986724e+07  3.986724e+07     3.986724e+07     3.986724e+07   \n",
      "mean     2.674640e-01  7.161389e+00     6.789741e+00     1.674815e-01   \n",
      "min      0.000000e+00  0.000000e+00     0.000000e+00     0.000000e+00   \n",
      "25%      0.000000e+00  0.000000e+00     0.000000e+00     0.000000e+00   \n",
      "50%      0.000000e+00  0.000000e+00     0.000000e+00     0.000000e+00   \n",
      "75%      0.000000e+00  7.480000e+00     5.500000e+00     0.000000e+00   \n",
      "max      3.057500e+02  6.633800e+02     6.633800e+02     2.075900e+02   \n",
      "std      3.555833e+00  1.511174e+01     1.469702e+01     1.955987e+00   \n",
      "\n",
      "          hrs_rndon  hrs_lpnadmin     hrs_natrn    incomplete  \n",
      "count  3.861363e+07  3.470814e+07  3.470814e+07  1.330459e+06  \n",
      "mean   5.059472e+00  6.233859e+00  4.478582e+00  3.868966e-02  \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "50%    8.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "75%    8.000000e+00  8.420000e+00  0.000000e+00  0.000000e+00  \n",
      "max    6.414800e+02  4.980600e+02  4.885000e+02  1.000000e+00  \n",
      "std    4.567279e+00  1.081313e+01  1.330331e+01  1.928543e-01  \n",
      "\n",
      "[8 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(panel_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e796eed-20ef-484a-b987-f28cc4bfea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cms_certification_number           0\n",
      "provider_name                    184\n",
      "city                               0\n",
      "state                              0\n",
      "county_name                        0\n",
      "county_fips                       92\n",
      "cy_qtr                             0\n",
      "year                               0\n",
      "quarter                            0\n",
      "workdate                           0\n",
      "mds_census                         0\n",
      "hrs_rn_don_admin                   0\n",
      "hrs_rn_don_emp                     0\n",
      "hrs_rn_don_ctr                     0\n",
      "hrs_rn_admin                       0\n",
      "hrs_rn_admin_emp                   0\n",
      "hrs_rn_admin_ctr                   0\n",
      "hrs_rn                             0\n",
      "hrs_rn_emp                         0\n",
      "hrs_rn_ctr                         0\n",
      "hrs_lpn_admin                      0\n",
      "hrs_lpn_admin_emp                  0\n",
      "hrs_lpn_admin_ctr                  0\n",
      "hrs_lpn                            0\n",
      "hrs_lpn_emp                        0\n",
      "hrs_lpn_ctr                        0\n",
      "hrs_cna                            0\n",
      "hrs_cna_emp                        0\n",
      "hrs_cna_ctr                        0\n",
      "hrs_na_trn                         0\n",
      "hrs_na_trn_emp                     0\n",
      "hrs_na_trn_ctr                     0\n",
      "hrs_medaide                        0\n",
      "hrs_medaide_emp                    0\n",
      "hrs_medaide_ctr                    0\n",
      "source_file                        0\n",
      "hrs_rndon                    1253610\n",
      "hrs_lpnadmin                 5159102\n",
      "hrs_natrn                    5159102\n",
      "incomplete                  38536783\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(panel_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a9ff9b4-cb6b-49da-b88c-dea47d519935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[coverage] Found 725 facility-months with <50% daily reporting\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 152. MiB for an array with shape (1, 39867242) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 52\u001b[0m\n\u001b[0;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39massign(outlier\u001b[38;5;241m=\u001b[39moutlier_mask)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     49\u001b[0m agg_daily \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     50\u001b[0m     agg_daily\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcms_certification_number\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m\"\u001b[39m], group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;241m.\u001b[39mapply(flag_outliers)\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[outliers] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magg_daily[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutlier\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m daily records flagged as outliers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 6. Remove underreported months + outliers\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1825\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1825\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj)\n\u001b[0;32m   1826\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1827\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[0;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1830\u001b[0m         ):\n\u001b[0;32m   1831\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1832\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1833\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1836\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1837\u001b[0m             )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1890\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1888\u001b[0m     not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n\u001b[1;32m-> 1890\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_applied_output(\n\u001b[0;32m   1891\u001b[0m     data,\n\u001b[0;32m   1892\u001b[0m     values,\n\u001b[0;32m   1893\u001b[0m     not_indexed_same,\n\u001b[0;32m   1894\u001b[0m     is_transform,\n\u001b[0;32m   1895\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1584\u001b[0m, in \u001b[0;36mDataFrameGroupBy._wrap_applied_output\u001b[1;34m(self, data, values, not_indexed_same, is_transform)\u001b[0m\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_constructor()\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_not_none, DataFrame):\n\u001b[1;32m-> 1584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concat_objects(\n\u001b[0;32m   1585\u001b[0m         values,\n\u001b[0;32m   1586\u001b[0m         not_indexed_same\u001b[38;5;241m=\u001b[39mnot_indexed_same,\n\u001b[0;32m   1587\u001b[0m         is_transform\u001b[38;5;241m=\u001b[39mis_transform,\n\u001b[0;32m   1588\u001b[0m     )\n\u001b[0;32m   1590\u001b[0m key_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39mresult_index \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_not_none, (np\u001b[38;5;241m.\u001b[39mndarray, Index)):\n\u001b[0;32m   1593\u001b[0m     \u001b[38;5;66;03m# GH#1738: values is list of arrays of unequal lengths\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;66;03m#  fall through to the outer else clause\u001b[39;00m\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;66;03m# TODO: sure this is right?  we used to do this\u001b[39;00m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;66;03m#  after raising AttributeError above\u001b[39;00m\n\u001b[0;32m   1597\u001b[0m     \u001b[38;5;66;03m# GH 18930\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1473\u001b[0m, in \u001b[0;36mGroupBy._concat_objects\u001b[1;34m(self, values, not_indexed_same, is_transform)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         result \u001b[38;5;241m=\u001b[39m concat(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, keys\u001b[38;5;241m=\u001b[39mkeys)\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m not_indexed_same:\n\u001b[1;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m concat(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n\u001b[0;32m   1475\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39m_get_axis(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n\u001b[0;32m   1476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:177\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    167\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ea_compat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 152. MiB for an array with shape (1, 39867242) and data type int32"
     ]
    }
   ],
   "source": [
    "# 1. Aggregate daily RN, LPN, NA\n",
    "agg_daily = (\n",
    "    panel_df\n",
    "    .groupby([\"cms_certification_number\", \"workdate\"], as_index=False)\n",
    "    .agg({\n",
    "        \"hrs_rn\": \"sum\",\n",
    "        \"hrs_lpn\": \"sum\",\n",
    "        \"hrs_cna\": \"sum\",\n",
    "    })\n",
    ")\n",
    "\n",
    "# 2. Total hours\n",
    "agg_daily[\"total_hours\"] = agg_daily[[\"hrs_rn\", \"hrs_lpn\", \"hrs_cna\"]].sum(axis=1)\n",
    "\n",
    "# 3. Add year-month column for monthly checks\n",
    "agg_daily[\"year_month\"] = agg_daily[\"workdate\"].dt.to_period(\"M\")\n",
    "\n",
    "# 4. Reporting coverage per facility-month\n",
    "days_in_month = agg_daily[\"workdate\"].dt.days_in_month\n",
    "agg_daily = agg_daily.assign(days_in_month=days_in_month)\n",
    "\n",
    "coverage = (\n",
    "    agg_daily.groupby([\"cms_certification_number\", \"year_month\"])\n",
    "    .agg(days_reported=(\"workdate\", \"nunique\"),\n",
    "         days_in_month=(\"days_in_month\", \"max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "coverage[\"coverage_ratio\"] = coverage[\"days_reported\"] / coverage[\"days_in_month\"]\n",
    "underreported = coverage[coverage[\"coverage_ratio\"] < 0.5]\n",
    "\n",
    "print(f\"[coverage] Found {len(underreported)} facility-months with <50% daily reporting\")\n",
    "\n",
    "# 5. Outlier detection per facility-month\n",
    "def flag_outliers(x, cols=(\"hrs_rn\",\"hrs_lpn\",\"hrs_cna\",\"total_hours\"), thresh=3.0):\n",
    "    \"\"\"\n",
    "    Flag daily rows where any hours column is more than thresh*std from mean\n",
    "    within facility-month.\n",
    "    \"\"\"\n",
    "    outlier_mask = pd.Series(False, index=x.index)\n",
    "    for col in cols:\n",
    "        mu = x[col].mean()\n",
    "        sigma = x[col].std()\n",
    "        if sigma > 0:\n",
    "            outlier_mask |= (np.abs(x[col] - mu) > thresh * sigma)\n",
    "    x = x.assign(outlier=outlier_mask)\n",
    "    return x\n",
    "\n",
    "agg_daily = (\n",
    "    agg_daily\n",
    "    .groupby([\"cms_certification_number\", \"year_month\"], group_keys=False)\n",
    "    .apply(flag_outliers)\n",
    ")\n",
    "\n",
    "print(f\"[outliers] {agg_daily['outlier'].sum():,} daily records flagged as outliers\")\n",
    "\n",
    "# 6. Remove underreported months + outliers\n",
    "valid_months = coverage.loc[coverage[\"coverage_ratio\"] >= 0.5,\n",
    "                            [\"cms_certification_number\",\"year_month\"]]\n",
    "agg_clean = (\n",
    "    agg_daily\n",
    "    .merge(valid_months, on=[\"cms_certification_number\",\"year_month\"])\n",
    "    .loc[lambda d: ~d[\"outlier\"]]\n",
    "    .drop(columns=[\"outlier\",\"days_in_month\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"[final] rows before={len(agg_daily):,}, after cleaning={len(agg_clean):,}\")\n",
    "\n",
    "agg_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1f940-56ae-406d-963e-36debdd0eb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
