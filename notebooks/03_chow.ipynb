{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b8d961-f599-49bc-a37d-f2946189980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INPUT ] C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_long.csv\n",
      "[OUTPUT] C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\ccn_group_transitions.csv\n",
      "[OUTPUT] C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\ccn_chow_summary.csv\n",
      "[save] transitions: C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\ccn_group_transitions.csv  rows=23,955\n",
      "[save] summary(all CCNs): C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\ccn_chow_summary.csv  rows=13,419\n",
      "[save] lite (all CCNs): C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\ccn_chow_lite.csv  rows=13,419  cols=12\n",
      "[diag] CCNs in long: 13419\n",
      "[diag] CCNs in trans: 9004\n",
      "[diag] CCNs in summary: 13419\n",
      "\n",
      "=== Quick diagnostics ===\n",
      "Transitions total: 23955\n",
      "CHOWs total     : 12120\n",
      "Share overridden by surname rule: 5.93% (of all transitions)\n",
      "\n",
      "CHOWs by year:\n",
      "year\n",
      "2017    1443\n",
      "2018    1624\n",
      "2019    1931\n",
      "2020    1424\n",
      "2021    2011\n",
      "2022    1400\n",
      "2023    1436\n",
      "2024     811\n",
      "2025      40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Bucket distribution (all transitions):\n",
      "bucket_label\n",
      "90–100    22239\n",
      "80–90       551\n",
      "50–60       506\n",
      "60–70       394\n",
      "70–80       258\n",
      "<50           7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# CHOW Engine for Facility Signatures (long form)\n",
    "#   - Primary turnover: percent-weight overlap\n",
    "#   - Fallback: names (Jaccard)\n",
    "#   - Surname override: prevent family handoffs from counting as CHOWs\n",
    "#   - Buckets preserved; study window filter\n",
    "#\n",
    "# Inputs:\n",
    "#   <PROJECT>/data/interim/facility_signatures_long.csv\n",
    "#\n",
    "# Outputs:\n",
    "#   <PROJECT>/data/interim/ccn_group_transitions.csv\n",
    "#   <PROJECT>/data/interim/ccn_chow_summary.csv\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import os, re, json, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# ------------------------------- Paths ----------------------------------------\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "while not (PROJECT_ROOT / \"data\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "INTERIM_DIR  = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_LONG   = INTERIM_DIR / \"facility_signatures_long.csv\"\n",
    "OUT_TRANS = INTERIM_DIR / \"ccn_group_transitions.csv\"\n",
    "OUT_SUM   = INTERIM_DIR / \"ccn_chow_summary.csv\"\n",
    "\n",
    "print(\"[INPUT ]\", IN_LONG)\n",
    "print(\"[OUTPUT]\", OUT_TRANS)\n",
    "print(\"[OUTPUT]\", OUT_SUM)\n",
    "\n",
    "# ------------------------------- Config ---------------------------------------\n",
    "THRESH_CHOW      = 50.0\n",
    "CUTOFF_DATE      = pd.Timestamp(\"2017-01-01\")\n",
    "BUCKET_LABELS    = {\n",
    "    0: \"<50\",\n",
    "    1: \"90–100\",\n",
    "    2: \"80–90\",\n",
    "    3: \"70–80\",\n",
    "    4: \"60–70\",\n",
    "    5: \"50–60\",\n",
    "    6: \"inconclusive\"\n",
    "}\n",
    "\n",
    "# Surname override controls\n",
    "ORG_MARKERS_RE   = re.compile(r\"\\b(LLC|INC|CORP|CORPORATION|L\\.L\\.C\\.|L\\.P\\.|LP|LLP|PLC|COMPANY|CO\\.?|HOLDINGS?|GROUP|TRUST|FUND|CAPITAL|PARTNERS(hip)?|HEALTH|CARE|AUTHORITY|HOSPITAL|CENTER|NURSING|HOME|OPERATING|MANAGEMENT)\\b\", re.I)\n",
    "TOKEN_RE         = re.compile(r\"[^\\w\\s]\")\n",
    "SURNAME_MIN_FRACTION_KEEP = 0.80   # if ≥80% of ownership (by % weight) remains within same surname family, don't CHOW\n",
    "USE_SURNAME_OVERRIDE       = True\n",
    "\n",
    "# ------------------------------- Helpers --------------------------------------\n",
    "def parse_list(j):\n",
    "    \"\"\"Parse JSON list from string; return [] if bad/NA.\"\"\"\n",
    "    try:\n",
    "        if pd.isna(j): return []\n",
    "        out = json.loads(j)\n",
    "        return out if isinstance(out, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def weight_map(names_list, pcts_list):\n",
    "    \"\"\"Return dict: owner -> pct (floats).\"\"\"\n",
    "    wm = defaultdict(float)\n",
    "    for n, p in zip(names_list, pcts_list):\n",
    "        try:\n",
    "            f = float(p)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if pd.isna(f):\n",
    "            continue\n",
    "        wm[str(n)] += f\n",
    "    return dict(wm)\n",
    "\n",
    "def pct_overlap(prev_map, curr_map):\n",
    "    \"\"\"Percent overlap in [0, 100]. Assumes both sides ~sum to 100 but handles drift.\"\"\"\n",
    "    if not prev_map and not curr_map:\n",
    "        return np.nan\n",
    "    owners = set(prev_map) | set(curr_map)\n",
    "    overlap = sum(min(prev_map.get(o, 0.0), curr_map.get(o, 0.0)) for o in owners)\n",
    "    denom   = max(sum(prev_map.values()), sum(curr_map.values()), 100.0)\n",
    "    return max(0.0, min(100.0 * overlap / denom, 100.0))\n",
    "\n",
    "def jaccard_names(prev_names, curr_names):\n",
    "    a, b = set(prev_names), set(curr_names)\n",
    "    if not a and not b:\n",
    "        return np.nan\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b) or 1\n",
    "    return inter / union\n",
    "\n",
    "def looks_like_person(name: str) -> bool:\n",
    "    \"\"\"Heuristic: treat as person if no org markers and has 1–3 word tokens.\"\"\"\n",
    "    if not name or ORG_MARKERS_RE.search(name):\n",
    "        return False\n",
    "    toks = TOKEN_RE.sub(\" \", str(name)).split()\n",
    "    toks = [t for t in toks if t]\n",
    "    return 1 <= len(toks) <= 3\n",
    "\n",
    "def surname_of(name: str) -> str:\n",
    "    \"\"\"Very simple surname getter: last token of a person-like name; else ''.\"\"\"\n",
    "    toks = TOKEN_RE.sub(\" \", str(name)).split()\n",
    "    toks = [t for t in toks if t]\n",
    "    return toks[-1].upper() if toks else \"\"\n",
    "\n",
    "def surname_weight_map(wm: dict) -> dict:\n",
    "    \"\"\"Aggregate owner weights by surname for person-like owners; others grouped as org_* buckets.\"\"\"\n",
    "    agg = defaultdict(float)\n",
    "    for n, p in wm.items():\n",
    "        if looks_like_person(n):\n",
    "            s = surname_of(n)\n",
    "            if s:\n",
    "                agg[s] += p\n",
    "            else:\n",
    "                agg[\"_PERSON_\"] += p\n",
    "        else:\n",
    "            agg[\"_ORG_\"] += p\n",
    "    return dict(agg)\n",
    "\n",
    "def surname_family_overlap(prev_wm: dict, curr_wm: dict) -> float:\n",
    "    \"\"\"Surname-level % overlap in [0,100] using surname-weight maps.\"\"\"\n",
    "    ps = surname_weight_map(prev_wm)\n",
    "    cs = surname_weight_map(curr_wm)\n",
    "    owners = set(ps) | set(cs)\n",
    "    overlap = sum(min(ps.get(k, 0.0), cs.get(k, 0.0)) for k in owners)\n",
    "    denom   = max(sum(ps.values()), sum(cs.values()), 100.0)\n",
    "    return max(0.0, min(100.0 * overlap / denom, 100.0))\n",
    "\n",
    "def bucket_code(turnover_pct: float) -> int:\n",
    "    if pd.isna(turnover_pct): return 6\n",
    "    t = float(turnover_pct)\n",
    "    if t < 50:  return 0\n",
    "    if t >= 90: return 1\n",
    "    if t >= 80: return 2\n",
    "    if t >= 70: return 3\n",
    "    if t >= 60: return 4\n",
    "    return 5  # 50–60\n",
    "\n",
    "# ------------------------------- Load -----------------------------------------\n",
    "long = pd.read_csv(IN_LONG, dtype={\"cms_certification_number\":\"string\"}, low_memory=False)\n",
    "# Parse dates & lists\n",
    "long[\"start\"] = pd.to_datetime(long[\"start\"], errors=\"coerce\")\n",
    "long[\"end\"]   = pd.to_datetime(long[\"end\"],   errors=\"coerce\")\n",
    "long[\"names\"] = long[\"names_list\"].apply(parse_list)\n",
    "long[\"pcts\"]  = long[\"pcts_list\"].apply(parse_list)\n",
    "\n",
    "# Defensive: ensure lists align (length mismatch should be rare here)\n",
    "bad_align = (long[\"names\"].str.len() != long[\"pcts\"].str.len())\n",
    "if int(bad_align.sum()) > 0:\n",
    "    print(f\"[warn] rows with names/pcts length mismatch: {int(bad_align.sum())}\")\n",
    "\n",
    "# -------------------------- Build transitions per CCN -------------------------\n",
    "rows = []\n",
    "\n",
    "for ccn, g in long.groupby(\"cms_certification_number\", sort=True):\n",
    "    g = g.sort_values(\"start\").reset_index(drop=True)\n",
    "    if len(g) < 2:\n",
    "        continue\n",
    "    for i in range(1, len(g)):\n",
    "        prev = g.loc[i-1]\n",
    "        curr = g.loc[i]\n",
    "        from_start = prev[\"start\"]\n",
    "        to_start   = curr[\"start\"]\n",
    "\n",
    "        prev_w = weight_map(prev[\"names\"], prev[\"pcts\"])\n",
    "        curr_w = weight_map(curr[\"names\"], curr[\"pcts\"])\n",
    "\n",
    "        # Primary: percent-based turnover\n",
    "        ov_pct    = pct_overlap(prev_w, curr_w)                # [0,100]\n",
    "        turn_pct  = None if pd.isna(ov_pct) else (100.0 - ov_pct)\n",
    "        method    = 0  # 0 = percent-based, 1 = names-based\n",
    "\n",
    "        # Fallback: names Jaccard if percent not available (should be rare)\n",
    "        if pd.isna(turn_pct):\n",
    "            jacc = jaccard_names(prev[\"names\"], curr[\"names\"])\n",
    "            turn_pct = None if pd.isna(jacc) else (100.0 * (1.0 - jacc))\n",
    "            method = 1\n",
    "\n",
    "        # Inconclusive if still NaN\n",
    "        inconclusive = pd.isna(turn_pct)\n",
    "\n",
    "        # Surname override: if same family keeps majority control, don't CHOW\n",
    "        surname_keep_pct = surname_family_overlap(prev_w, curr_w)  # [0,100]\n",
    "        surname_override = False\n",
    "        if USE_SURNAME_OVERRIDE and not pd.isna(turn_pct):\n",
    "            if surname_keep_pct >= 100.0 * SURNAME_MIN_FRACTION_KEEP:\n",
    "                surname_override = True\n",
    "\n",
    "        # Bucket\n",
    "        bcode = bucket_code(turn_pct)\n",
    "\n",
    "        # CHOW decision (study window + threshold + not overridden)\n",
    "        is_in_window = (pd.notna(to_start) and to_start >= CUTOFF_DATE)\n",
    "        is_chow = bool(is_in_window and (not inconclusive) and (turn_pct >= THRESH_CHOW) and (not surname_override))\n",
    "\n",
    "        rows.append({\n",
    "            \"cms_certification_number\": ccn,\n",
    "            \"from_group\": int(prev[\"group_n\"]),\n",
    "            \"to_group\":   int(curr[\"group_n\"]),\n",
    "            \"from_start\": from_start,\n",
    "            \"from_end\":   prev[\"end\"],\n",
    "            \"to_start\":   to_start,\n",
    "            \"to_end\":     curr[\"end\"],\n",
    "            \"from_level\": prev[\"source_level\"],\n",
    "            \"to_level\":   curr[\"source_level\"],\n",
    "            \"turnover_pct\": None if pd.isna(turn_pct) else round(float(turn_pct), 1),\n",
    "            \"overlap_pct\":  None if pd.isna(ov_pct)   else round(float(ov_pct), 1),\n",
    "            \"method\":       method,              # 0=percent, 1=names\n",
    "            \"bucket_code\":  bcode,\n",
    "            \"bucket_label\": BUCKET_LABELS[bcode],\n",
    "            \"surname_keep_pct\": round(float(surname_keep_pct), 1) if not pd.isna(surname_keep_pct) else np.nan,\n",
    "            \"surname_override\": surname_override,\n",
    "            \"inconclusive\": inconclusive,\n",
    "            \"is_chow\": is_chow\n",
    "        })\n",
    "\n",
    "trans = pd.DataFrame(rows).sort_values(\n",
    "    [\"cms_certification_number\",\"to_start\",\"to_group\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# -------------------------- Save transitions ----------------------------------\n",
    "trans.to_csv(OUT_TRANS, index=False)\n",
    "print(f\"[save] transitions: {OUT_TRANS}  rows={len(trans):,}\")\n",
    "\n",
    "# Universe of CCNs (even those with 0 transitions)\n",
    "all_ccns = (\n",
    "    long[[\"cms_certification_number\",\"start\"]]\n",
    "    .groupby(\"cms_certification_number\", as_index=False)\n",
    "    .agg(first_seen=(\"start\",\"min\"))\n",
    ")\n",
    "\n",
    "# Helper: summarize a single CCN's transition records (may be empty)\n",
    "def summarize_ccn_safe(ccn, df_ccn, max_events=12):\n",
    "    out = {\n",
    "        \"cms_certification_number\": ccn,\n",
    "        \"num_chows\": 0,\n",
    "        \"first_seen_month\": pd.NaT,\n",
    "        \"present_at_start\": False,\n",
    "        \"entered_after_start\": False,\n",
    "    }\n",
    "    # bucket counts 0..6\n",
    "    for k in range(0,7):\n",
    "        out[f\"bucket_{k}_count\"] = 0\n",
    "\n",
    "    if df_ccn is None or df_ccn.empty:\n",
    "        return out  # zero CHOWs, no transitions\n",
    "\n",
    "    df_ccn = df_ccn.sort_values(\"to_start\")\n",
    "    # bucket histogram (all transitions, including <2017 for diagnostics)\n",
    "    bc = df_ccn[\"bucket_code\"].value_counts().to_dict()\n",
    "    for k in range(0,7):\n",
    "        out[f\"bucket_{k}_count\"] = int(bc.get(k, 0))\n",
    "\n",
    "    # CHOWs in the study window\n",
    "    chow = df_ccn[df_ccn[\"is_chow\"]].copy()\n",
    "    out[\"num_chows\"] = int(chow.shape[0])\n",
    "\n",
    "    # dates/magnitudes/methods up to max_events\n",
    "    for i, (_, r) in enumerate(chow.head(max_events).iterrows(), start=1):\n",
    "        out[f\"chow_date_{i}\"]      = r[\"to_start\"]\n",
    "        out[f\"chow_magnitude_{i}\"] = r.get(\"turnover_pct\", np.nan)\n",
    "        out[f\"chow_method_{i}\"]    = r.get(\"method\", np.nan)       # 0=percent,1=names\n",
    "        out[f\"chow_inconcl_{i}\"]   = bool(r.get(\"inconclusive\", False))\n",
    "\n",
    "    return out\n",
    "\n",
    "# Build a dict of transitions by CCN for quick lookup (may be empty for some)\n",
    "trans_by_ccn = {k: v.copy() for k, v in trans.groupby(\"cms_certification_number\")} if not trans.empty else {}\n",
    "\n",
    "summary_rows = []\n",
    "for _, row in all_ccns.iterrows():\n",
    "    ccn = row[\"cms_certification_number\"]\n",
    "    s   = summarize_ccn_safe(ccn, trans_by_ccn.get(ccn))\n",
    "    # fill first-seen / present-at-start flags from long file\n",
    "    first_seen = long.loc[long[\"cms_certification_number\"]==ccn, \"start\"].min()\n",
    "    s[\"first_seen_month\"]  = first_seen.to_period(\"M\").to_timestamp(\"M\") if pd.notna(first_seen) else pd.NaT\n",
    "    s[\"present_at_start\"]  = bool(pd.notna(first_seen) and (first_seen <  CUTOFF_DATE))\n",
    "    s[\"entered_after_start\"] = bool(pd.notna(first_seen) and (first_seen >= CUTOFF_DATE))\n",
    "    summary_rows.append(s)\n",
    "\n",
    "summary = (\n",
    "    pd.DataFrame(summary_rows)\n",
    "      .sort_values(\"cms_certification_number\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "summary.to_csv(OUT_SUM, index=False)\n",
    "print(f\"[save] summary(all CCNs): {OUT_SUM}  rows={len(summary):,}\")\n",
    "\n",
    "# --- LITE EXPORT (always all CCNs) ---\n",
    "chow_date_cols = [c for c in summary.columns if c.startswith(\"chow_date_\")]\n",
    "lite = summary[[\"cms_certification_number\",\"num_chows\"] + chow_date_cols].copy()\n",
    "lite[\"is_chow\"] = (lite[\"num_chows\"] > 0).astype(int)\n",
    "lite = lite[[\"cms_certification_number\",\"num_chows\",\"is_chow\"] + chow_date_cols]\n",
    "OUT_LITE = INTERIM_DIR / \"ccn_chow_lite.csv\"\n",
    "lite.to_csv(OUT_LITE, index=False)\n",
    "print(f\"[save] lite (all CCNs): {OUT_LITE}  rows={len(lite):,}  cols={len(lite.columns)}\")\n",
    "\n",
    "# --- Quick sanity:\n",
    "print(\"[diag] CCNs in long:\", long['cms_certification_number'].nunique())\n",
    "print(\"[diag] CCNs in trans:\", trans['cms_certification_number'].nunique() if not trans.empty else 0)\n",
    "print(\"[diag] CCNs in summary:\", summary['cms_certification_number'].nunique())\n",
    "# -------------------------- Quick prints --------------------------------------\n",
    "print(\"\\n=== Quick diagnostics ===\")\n",
    "if not trans.empty:\n",
    "    print(\"Transitions total:\", len(trans))\n",
    "    print(\"CHOWs total     :\", int(trans[\"is_chow\"].sum()))\n",
    "    print(\"Share overridden by surname rule:\",\n",
    "          f\"{100.0*trans.loc[trans['surname_override'],'is_chow'].count()/max(1,len(trans)):.2f}% (of all transitions)\")\n",
    "    print(\"\\nCHOWs by year:\")\n",
    "    print(trans[trans[\"is_chow\"]].assign(year=pd.to_datetime(trans[\"to_start\"]).dt.year)\n",
    "              .groupby(\"year\").size().rename(\"count\"))\n",
    "\n",
    "print(\"\\nBucket distribution (all transitions):\")\n",
    "print(trans[\"bucket_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779c1d24-f302-4822-b151-37ea38642cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] wrote C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\ccn_chow_lite.csv with 13419 rows and 12 cols\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "while not (PROJECT_ROOT / \"data\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "INTERIM_DIR  = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "\n",
    "IN_SUM  = INTERIM_DIR / \"ccn_chow_summary.csv\"\n",
    "OUT_LITE = INTERIM_DIR / \"ccn_chow_lite.csv\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(IN_SUM, dtype={\"cms_certification_number\":\"string\"}, low_memory=False)\n",
    "\n",
    "# Find chow_date columns dynamically\n",
    "chow_date_cols = [c for c in df.columns if c.startswith(\"chow_date_\")]\n",
    "\n",
    "# Build lite frame\n",
    "lite = df[[\"cms_certification_number\",\"num_chows\"] + chow_date_cols].copy()\n",
    "lite[\"is_chow\"] = (lite[\"num_chows\"] > 0).astype(int)\n",
    "\n",
    "# Reorder: ccn, num_chows, is_chow, then chow dates\n",
    "cols = [\"cms_certification_number\",\"num_chows\",\"is_chow\"] + chow_date_cols\n",
    "lite = lite[cols]\n",
    "\n",
    "# Save\n",
    "lite.to_csv(OUT_LITE, index=False)\n",
    "print(f\"[save] wrote {OUT_LITE} with {len(lite)} rows and {len(lite.columns)} cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba1ddb-19e3-4cf5-bc93-e25eac739786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
