{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807a5892-ac93-4ea9-9ceb-f895ffcb72c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures.csv\n",
      "OUTPUT: C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_groupflags.csv\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 0.  Portable path setup  (no src import required)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "import os, re, pathlib, pandas as pd, numpy as np\n",
    "\n",
    "# locate repo root (folder that contains \"data\")\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "while not (PROJECT_ROOT / \"data\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "RAW_DIR      = pathlib.Path(os.getenv(\"NH_DATA_DIR\", PROJECT_ROOT / \"data\" / \"raw\"))\n",
    "INTERIM_DIR  = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SIG_PATH  = INTERIM_DIR / \"facility_signatures.csv\"\n",
    "OUT_PATH  = INTERIM_DIR / \"facility_signatures_groupflags.csv\"\n",
    "print(\"INPUT :\", SIG_PATH)\n",
    "print(\"OUTPUT:\", OUT_PATH)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# config  (add one switch)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "THRESH              = 50.0                      # % equity turnover\n",
    "CUTOFF_DATE         = pd.Timestamp(\"2017-01-01\")\n",
    "USE_SURNAME_OVERRIDE= True\n",
    "LOOK_THROUGH_LLC    = True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ecc447-fdd4-42df-bbe1-b3560bde23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] 14,075 rows, 66 cols\n",
      "[groups] detected: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Load signature-wide table & detect group numbers\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "sig = pd.read_csv(SIG_PATH, dtype={\"cms_certification_number\":\"string\"}, low_memory=False)\n",
    "print(f\"[load] {len(sig):,} rows, {sig.shape[1]} cols\")\n",
    "\n",
    "# drop any legacy chow columns\n",
    "sig = sig.loc[:, ~sig.columns.str.startswith(\"chow\")]\n",
    "group_nums = sorted(\n",
    "    int(m.group(1))\n",
    "    for c in sig.columns\n",
    "    if (m := re.search(r\"group(\\d+)_owners$\", c))\n",
    ")\n",
    "print(\"[groups] detected:\", group_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d040d2-1cbf-4cdd-84cc-8fd4167aa0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[long] 39,789 group rows\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 2. WIDE → LONG helper  (now also grabs groupN_roles)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def sig_wide_to_long(sig_df, group_nums):\n",
    "    recs = []\n",
    "    for _, row in sig_df.iterrows():\n",
    "        ccn  = row[\"cms_certification_number\"]\n",
    "        prov = row[\"provider_name\"]\n",
    "        for n in group_nums:\n",
    "            owners = row.get(f\"group{n}_owners\")\n",
    "            pcts   = row.get(f\"group{n}_pcts\")\n",
    "            roles  = row.get(f\"group{n}_roles\")          # ← NEW\n",
    "            date   = row.get(f\"group{n}_date\")\n",
    "            if (pd.isna(owners) or owners == \"\") and (pd.isna(date) or date == \"\"):\n",
    "                continue\n",
    "            recs.append((ccn, prov, n, owners, pcts, roles, date))\n",
    "    long = pd.DataFrame(\n",
    "        recs,\n",
    "        columns=[\"cms_certification_number\",\"provider_name\",\"grp_n\",\n",
    "                 \"owners\",\"pcts\",\"roles\",\"date_str\"]\n",
    "    )\n",
    "    long[\"date\"] = pd.to_datetime(long[\"date_str\"], errors=\"coerce\")\n",
    "    return long\n",
    "\n",
    "long = sig_wide_to_long(sig, group_nums)          # ← create the variable\n",
    "print(f\"[long] {len(long):,} group rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1948b8bb-ef20-4e7f-895e-9ac5d64eded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Parse owner, pct *and* role strings\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "split_pipe = lambda s: [] if pd.isna(s) or s==\"\" else [x.strip() for x in str(s).split(\"|\")]\n",
    "pct_re     = re.compile(r\"(\\d+(?:\\.\\d+)?)\")\n",
    "pct_float  = lambda s: float(pct_re.search(str(s)).group(1)) if pct_re.search(str(s)) else np.nan\n",
    "\n",
    "long[\"owners_list\"] = long[\"owners\"].apply(split_pipe)\n",
    "long[\"pcts_list\"]   = long[\"pcts\"].apply(split_pipe)\n",
    "long[\"roles_list\"]  = long[\"roles\"].apply(split_pipe)       # ← NEW\n",
    "long[\"pcts_num\"]    = long[\"pcts_list\"].apply(lambda lst: [pct_float(x) for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48484483-22f0-471b-8ebe-4af7aeaa2a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has 'turnover' column? -> False\n",
      "Pairs with pct on BOTH sides: 35.53 %\n",
      "Total pairs: 25714\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: what percent of pairs got a real turnover? what % have all percents missing?\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# 1) ensure turnover exists\n",
    "print(\"Has 'turnover' column? ->\", \"turnover\" in long.columns)\n",
    "\n",
    "# 2) compute pair diagnostics without changing your data\n",
    "def pair_stats(group):\n",
    "    group = group.sort_values(\"date\")\n",
    "    rows = []\n",
    "    for prev, curr in zip(group.iloc[:-1].itertuples(index=False), group.iloc[1:].itertuples(index=False)):\n",
    "        # usable % counts\n",
    "        prev_p = sum(0 if (v is None or (isinstance(v,float) and np.isnan(v))) else 1 for v in getattr(prev,\"pcts_num\"))\n",
    "        curr_p = sum(0 if (v is None or (isinstance(v,float) and np.isnan(v))) else 1 for v in getattr(curr,\"pcts_num\"))\n",
    "        rows.append({\n",
    "            \"ccn\": getattr(curr,\"cms_certification_number\"),\n",
    "            \"grp\": getattr(curr,\"grp_n\"),\n",
    "            \"date\": getattr(curr,\"date\"),\n",
    "            \"prev_has_pct\": prev_p>0,\n",
    "            \"curr_has_pct\": curr_p>0,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "pairs = pd.concat([pair_stats(g) for _, g in long.groupby(\"cms_certification_number\")], ignore_index=True)\n",
    "pct_pairs_with_any_pct = (pairs[\"prev_has_pct\"] & pairs[\"curr_has_pct\"]).mean()\n",
    "print(\"Pairs with pct on BOTH sides:\", round(100*pct_pairs_with_any_pct,2), \"%\")\n",
    "print(\"Total pairs:\", len(pairs))\n",
    "\n",
    "# If turnover exists, show how many are non-NA and above threshold\n",
    "if \"turnover\" in long.columns:\n",
    "    non_na = long[\"turnover\"].notna().sum()\n",
    "    print(\"turnover non-NA rows:\", non_na)\n",
    "    if non_na:\n",
    "        print(long.loc[long[\"turnover\"].notna(), \"turnover\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6078345f-9404-4fb5-b843-0dc80b0a6f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[turnover] non-NA rows: 14557\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 4. %-equity turnover that can look through LLC shells\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "LLC_RE = re.compile(r\"\\b(LLC|INC|CORP|L\\.L\\.C\\.|L\\.P\\.|CO\\.?)\\b\", re.I)\n",
    "\n",
    "def build_dict(row, look_through=True):\n",
    "    owners = row[\"owners_list\"]\n",
    "    pcts   = row[\"pcts_num\"]\n",
    "    roles  = row.get(\"roles_list\", [\"DIRECT\"] * len(owners))  # safe default\n",
    "    any_indirect = any((r or \"\").strip().upper() == \"INDIRECT\" for r in roles)\n",
    "\n",
    "    recs = []\n",
    "    for o, p, r in zip(owners, pcts, roles):\n",
    "        if np.isnan(p):\n",
    "            continue\n",
    "        # only treat DIRECT corporate shells as pass-through if we *have* indirect detail\n",
    "        if look_through and any_indirect and (r or \"\").upper() == \"DIRECT\" and LLC_RE.search(o):\n",
    "            continue\n",
    "        recs.append((o, float(p)))\n",
    "\n",
    "    d = {}\n",
    "    for o, p in recs:\n",
    "        d[o] = d.get(o, 0.0) + p\n",
    "    return d\n",
    "\n",
    "def pct_turnover(prev, curr, look_through=True):\n",
    "    prev_d = build_dict(prev, look_through=look_through)\n",
    "    curr_d = build_dict(curr, look_through=look_through)\n",
    "    if not prev_d and not curr_d:\n",
    "        return np.nan\n",
    "    owners = set(prev_d) | set(curr_d)\n",
    "    diff   = sum(abs(curr_d.get(o, 0.0) - prev_d.get(o, 0.0)) for o in owners)\n",
    "    return diff / 2.0\n",
    "\n",
    "if \"turnover\" not in long.columns:\n",
    "    long = long.sort_values(\n",
    "        [\"cms_certification_number\", \"date\", \"grp_n\"]\n",
    "    ).reset_index(drop=True)\n",
    "    long[\"turnover\"] = np.nan\n",
    "\n",
    "    for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "        idxs = sorted(idxs)\n",
    "        for i in range(1, len(idxs)):  # compare each group to its previous group\n",
    "            long.loc[idxs[i], \"turnover\"] = pct_turnover(\n",
    "                long.loc[idxs[i - 1]],\n",
    "                long.loc[idxs[i]],\n",
    "                look_through=LOOK_THROUGH_LLC\n",
    "            )\n",
    "\n",
    "print(\"[turnover] non-NA rows:\", long[\"turnover\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74ad8ca-d23f-47a7-a477-0c62f58535a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 5. Surname continuity override\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "surname_set = lambda lst: { (n.split(\",\")[0] if \",\" in n else n.split()[0]).strip().upper()\n",
    "                            for n in lst if n.strip() }\n",
    "\n",
    "long[\"surnames_set\"] = long[\"owners_list\"].apply(surname_set)\n",
    "long[\"surname_overlap_prev\"] = False\n",
    "if USE_SURNAME_OVERRIDE:\n",
    "    for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "        idxs = sorted(idxs)\n",
    "        for i in range(1, len(idxs)):\n",
    "            overlap = bool(long.loc[idxs[i-1],\"surnames_set\"] & long.loc[idxs[i], \"surnames_set\"])\n",
    "            long.loc[idxs[i], \"surname_overlap_prev\"] = overlap\n",
    "\n",
    "# after you compute surname_overlap_prev in §5:\n",
    "long[\"eff_turnover\"] = long[\"turnover\"]\n",
    "mask_na = long[\"eff_turnover\"].isna()\n",
    "long.loc[mask_na & ~long[\"surname_overlap_prev\"], \"eff_turnover\"] = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d7791c-7806-413f-8cbd-1f13110cfbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshots with any INDIRECT: 22009\n",
      "rows with owners/roles length mismatch: 0\n"
     ]
    }
   ],
   "source": [
    "# How many snapshots even mention INDIRECT owners?\n",
    "long[\"has_indirect\"] = long[\"roles_list\"].apply(\n",
    "    lambda rs: any((r or \"\").upper() == \"INDIRECT\" for r in (rs or []))\n",
    ")\n",
    "print(\"snapshots with any INDIRECT:\", long[\"has_indirect\"].sum())\n",
    "\n",
    "# Are roles aligned with owners? (lengths should match)\n",
    "def len_mismatch(row):\n",
    "    return len(row[\"owners_list\"]) != len(row.get(\"roles_list\", []))\n",
    "print(\"rows with owners/roles length mismatch:\",\n",
    "      long.apply(len_mismatch, axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6e9bee4-9e65-4266-9efd-ee952ebc2351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[chow] groups flagged: 11,229\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 6. Apply ChOW rules\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "long[\"is_chow\"]  = False\n",
    "long[\"chow_date\"] = pd.NaT\n",
    "\n",
    "for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "    idxs = sorted(idxs)\n",
    "    # baseline group (group1)\n",
    "    first = idxs[0]\n",
    "    if pd.notna(long.loc[first,\"date\"]) and long.loc[first,\"date\"] >= CUTOFF_DATE:\n",
    "        long.loc[first,\"is_chow\"] = True\n",
    "        long.loc[first,\"chow_date\"] = long.loc[first,\"date\"]\n",
    "    # subsequent groups\n",
    "    # subsequent groups\n",
    "    for i in range(1, len(idxs)):\n",
    "        condition = (\n",
    "            (long.loc[idxs[i], \"eff_turnover\"] >= THRESH) &\n",
    "            (long.loc[idxs[i], \"date\"] >= CUTOFF_DATE)\n",
    "    )\n",
    "    # (optional) drop the extra surname veto since eff_turnover already uses it\n",
    "    # if USE_SURNAME_OVERRIDE:\n",
    "    #     condition &= ~long.loc[idxs[i], \"surname_overlap_prev\"]\n",
    "\n",
    "        if condition:\n",
    "            long.loc[idxs[i], \"is_chow\"] = True\n",
    "\n",
    "print(f\"[chow] groups flagged: {long['is_chow'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac1cdb8-5c8b-44a9-9d6f-2afd230756a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[final] facility_signatures_groupflags shape: (14075, 98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21148\\2714148803.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  w_is  = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"is_chow\").fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 7. LONG → WIDE  (is_chow, chow_date flags)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "w_is  = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"is_chow\").fillna(False)\n",
    "w_cd  = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"chow_date\")\n",
    "\n",
    "w_is.columns = [f\"group{n}_is_chow\"  for n in w_is.columns]\n",
    "w_cd.columns = [f\"group{n}_chow_date\" for n in w_cd.columns]\n",
    "w_is = w_is.replace({True:\"Yes\", False:\"\"})\n",
    "\n",
    "# combine with original signature-wide table\n",
    "sig_chow = (\n",
    "    sig.set_index(\"cms_certification_number\")\n",
    "       .join(w_is, how=\"left\")\n",
    "       .join(w_cd, how=\"left\")\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "# reorder columns\n",
    "def order_cols(df):\n",
    "    grp_nums = sorted(int(re.search(r\"group(\\d+)_owners$\", c).group(1))\n",
    "                      for c in df.columns if re.search(r\"group(\\d+)_owners$\", c))\n",
    "    cols = [\"cms_certification_number\", \"provider_name\"]\n",
    "    for n in grp_nums:\n",
    "        cols += [f\"group{n}_owners\", f\"group{n}_pcts\", f\"group{n}_roles\", f\"group{n}_date\",\n",
    "                 f\"group{n}_is_chow\", f\"group{n}_chow_date\"]\n",
    "    return cols\n",
    "\n",
    "sig_chow = sig_chow[order_cols(sig_chow)]\n",
    "print(f\"[final] facility_signatures_groupflags shape: {sig_chow.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b9a796-6f1e-4484-846d-fc12a06571c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] wrote C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_groupflags.csv\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 8. SAVE\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "sig_chow.to_csv(OUT_PATH, index=False)\n",
    "print(f\"[save] wrote {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed06a8b1-acc4-4ebb-83fd-2f438c415ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[turnover] non-NA: 14557 of 25714 pairs\n",
      "[flags] group1: 701  groups≥2: 10528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21148\\3802522757.py:116: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  w_is = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"is_chow\").fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] wrote C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_groupflags.csv\n"
     ]
    }
   ],
   "source": [
    "# ---- CONFIG ----\n",
    "THRESH = 50.0\n",
    "CUTOFF_DATE = pd.Timestamp(\"2017-01-01\")\n",
    "LOOK_THROUGH_LLC = True\n",
    "SIG_PATH = INTERIM_DIR / \"facility_signatures.csv\"\n",
    "OUT_PATH = INTERIM_DIR / \"facility_signatures_groupflags.csv\"\n",
    "\n",
    "import re, numpy as np, pandas as pd\n",
    "\n",
    "# ---- LOAD & WIDE->LONG ----\n",
    "sig = pd.read_csv(SIG_PATH, dtype={\"cms_certification_number\":\"string\"}, low_memory=False)\n",
    "group_nums = sorted(int(re.search(r\"group(\\d+)_owners$\", c).group(1)) for c in sig.columns if re.search(r\"group(\\d+)_owners$\", c))\n",
    "\n",
    "def split_pipe(s): \n",
    "    return [] if (pd.isna(s) or str(s).strip()==\"\") else [x.strip() for x in str(s).split(\"|\")]\n",
    "pct_re = re.compile(r\"(\\d+(?:\\.\\d+)?)\")\n",
    "pct_float = lambda s: float(pct_re.search(str(s)).group(1)) if pct_re.search(str(s)) else np.nan\n",
    "\n",
    "recs=[]\n",
    "for _, row in sig.iterrows():\n",
    "    ccn=row[\"cms_certification_number\"]; prov=row.get(\"provider_name\",\"\")\n",
    "    for n in group_nums:\n",
    "        owners=row.get(f\"group{n}_owners\"); pcts=row.get(f\"group{n}_pcts\")\n",
    "        roles=row.get(f\"group{n}_roles\"); date=row.get(f\"group{n}_date\")\n",
    "        if (pd.isna(owners) or owners==\"\") and (pd.isna(date) or date==\"\"): \n",
    "            continue\n",
    "        recs.append((ccn,prov,n,owners,pcts,roles,date))\n",
    "long = pd.DataFrame(recs, columns=[\"cms_certification_number\",\"provider_name\",\"grp_n\",\"owners\",\"pcts\",\"roles\",\"date_str\"])\n",
    "long[\"date\"] = pd.to_datetime(long[\"date_str\"], errors=\"coerce\")\n",
    "long[\"owners_list\"] = long[\"owners\"].apply(split_pipe)\n",
    "long[\"pcts_list\"]   = long[\"pcts\"].apply(split_pipe)\n",
    "long[\"pcts_num\"]    = long[\"pcts_list\"].apply(lambda lst: [pct_float(x) for x in lst])\n",
    "long[\"roles_list\"]  = long[\"roles\"].apply(split_pipe)\n",
    "\n",
    "# quick alignment check\n",
    "misalign = (long[\"owners_list\"].str.len() != long[\"pcts_num\"].str.len()) | (long[\"owners_list\"].str.len() != long[\"roles_list\"].str.len())\n",
    "assert not misalign.any(), f\"Owner/pct/role length mismatch in {misalign.sum()} rows\"\n",
    "\n",
    "# ---- TURNOVER (with guarded look-through) ----\n",
    "LLC_RE = re.compile(r\"\\b(LLC|INC|CORP|L\\.L\\.C\\.|L\\.P\\.|CO\\.?)\\b\", re.I)\n",
    "def build_dict(row, look_through=True):\n",
    "    owners, pcts, roles = row[\"owners_list\"], row[\"pcts_num\"], row[\"roles_list\"]\n",
    "    any_indirect = any((r or \"\").strip().upper()==\"INDIRECT\" for r in roles)\n",
    "    recs=[]\n",
    "    for o,p,r in zip(owners,pcts,roles):\n",
    "        if np.isnan(p): \n",
    "            continue\n",
    "        if look_through and any_indirect and (r or \"\").upper()==\"DIRECT\" and LLC_RE.search(o):\n",
    "            continue\n",
    "        recs.append((o, float(p)))\n",
    "    d={}\n",
    "    for o,p in recs:\n",
    "        d[o]=d.get(o,0.0)+p\n",
    "    return d\n",
    "\n",
    "def pct_turnover(prev, curr, look_through=True):\n",
    "    prev_d = build_dict(prev, look_through)\n",
    "    curr_d = build_dict(curr, look_through)\n",
    "    if not prev_d and not curr_d: \n",
    "        return np.nan\n",
    "    owners = set(prev_d) | set(curr_d)\n",
    "    diff = sum(abs(curr_d.get(o,0.0)-prev_d.get(o,0.0)) for o in owners)\n",
    "    return diff/2.0\n",
    "\n",
    "long = long.sort_values([\"cms_certification_number\",\"date\",\"grp_n\"]).reset_index(drop=True)\n",
    "long[\"turnover\"] = np.nan\n",
    "pairs = 0\n",
    "for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "    idxs = sorted(idxs)\n",
    "    for i in range(1, len(idxs)):\n",
    "        pairs += 1\n",
    "        long.loc[idxs[i], \"turnover\"] = pct_turnover(long.loc[idxs[i-1]], long.loc[idxs[i]], look_through=LOOK_THROUGH_LLC)\n",
    "print(\"[turnover] non-NA:\", long[\"turnover\"].notna().sum(), \"of\", pairs, \"pairs\")\n",
    "\n",
    "# ---- FALLBACK (names) ----\n",
    "def surname_set(lst):\n",
    "    out=set()\n",
    "    for n in lst:\n",
    "        n=str(n).strip()\n",
    "        if not n: continue\n",
    "        out.add((n.split(\",\")[0] if \",\" in n else n.split()[0]).upper())\n",
    "    return out\n",
    "long[\"surnames_set\"] = long[\"owners_list\"].apply(surname_set)\n",
    "long[\"surname_overlap_prev\"] = False\n",
    "for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "    idxs = sorted(idxs)\n",
    "    for i in range(1, len(idxs)):\n",
    "        long.loc[idxs[i], \"surname_overlap_prev\"] = bool(long.loc[idxs[i-1],\"surnames_set\"] & long.loc[idxs[i],\"surnames_set\"])\n",
    "\n",
    "long[\"eff_turnover\"] = long[\"turnover\"]\n",
    "mask_na = long[\"eff_turnover\"].isna()\n",
    "long.loc[mask_na & ~long[\"surname_overlap_prev\"], \"eff_turnover\"] = 100.0\n",
    "\n",
    "# ---- FLAG ----\n",
    "long[\"is_chow\"] = False\n",
    "long[\"chow_date\"] = pd.NaT\n",
    "for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "    idxs = sorted(idxs)\n",
    "    # baseline\n",
    "    first = idxs[0]\n",
    "    if pd.notna(long.loc[first,\"date\"]) and long.loc[first,\"date\"] >= CUTOFF_DATE:\n",
    "        long.loc[first, [\"is_chow\",\"chow_date\"]] = [True, long.loc[first,\"date\"]]\n",
    "    # groups 2+\n",
    "    for i in range(1, len(idxs)):\n",
    "        if (pd.notna(long.loc[idxs[i], \"date\"]) and\n",
    "            long.loc[idxs[i], \"date\"] >= CUTOFF_DATE and\n",
    "            pd.notna(long.loc[idxs[i], \"eff_turnover\"]) and\n",
    "            long.loc[idxs[i], \"eff_turnover\"] >= THRESH):\n",
    "            long.loc[idxs[i], [\"is_chow\",\"chow_date\"]] = [True, long.loc[idxs[i], \"date\"]]\n",
    "\n",
    "g1 = (long.query(\"grp_n==1\")[\"is_chow\"]==True).sum()\n",
    "g2p = (long.query(\"grp_n>1\")[\"is_chow\"]==True).sum()\n",
    "print(f\"[flags] group1: {g1}  groups≥2: {g2p}\")\n",
    "\n",
    "# ---- SAVE BACK TO WIDE ----\n",
    "w_is = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"is_chow\").fillna(False)\n",
    "w_cd = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"chow_date\")\n",
    "w_is.columns = [f\"group{n}_is_chow\" for n in w_is.columns]\n",
    "w_cd.columns = [f\"group{n}_chow_date\" for n in w_cd.columns]\n",
    "w_is = w_is.replace({True:\"Yes\", False:\"\"})\n",
    "\n",
    "sig_chow = (\n",
    "    sig.set_index(\"cms_certification_number\")\n",
    "       .join(w_is, how=\"left\")\n",
    "       .join(w_cd, how=\"left\")\n",
    "       .reset_index()\n",
    ")\n",
    "sig_chow.to_csv(OUT_PATH, index=False)\n",
    "print(f\"[save] wrote {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dc9d3-51f2-498c-b8c4-a8405f325cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
