{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a246da-b7cc-4fb1-86fe-7d25bb7a68d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures.csv\n",
      "OUTPUT: C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_groupflags.csv\n",
      "[load] 14,075 rows, 66 cols\n",
      "[groups] detected: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[align] owner/pct/role length mismatches: 0\n",
      "[turnover] computed for pairs: 25693  non-NA: 14540\n",
      "[flags] total CHOW group rows: 9,809\n",
      "\n",
      "[CHOW by year — after A–E fixes]\n",
      "      flags  % via name heuristic\n",
      "year                             \n",
      "2017   1314                  15.4\n",
      "2018   1326                  27.1\n",
      "2019   1685                  28.3\n",
      "2020   1161                  35.3\n",
      "2021   1565                  39.3\n",
      "2022   1173                  10.4\n",
      "2023   1014                  16.2\n",
      "2024    543                  26.5\n",
      "2025     28                  10.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_31164\\3349587965.py:251: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  w_is = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"is_chow\").fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] wrote C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_groupflags.csv\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# CHOW Flagging — tightened logic with A–E fixes\n",
    "#   A) Replace 100%-fallback with cautious, names-only heuristic\n",
    "#   B) Normalize corporate owner names before turnover\n",
    "#   C) Collapse same‑day multi‑group hops per facility\n",
    "#   D) Stricter new‑home (group1) rule: require at least one owner %\n",
    "#   E) CHOW condition unchanged but now uses safer eff_turnover\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "import os, re, pathlib, numpy as np, pandas as pd\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 0) Paths / config\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "while not (PROJECT_ROOT / \"data\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "RAW_DIR      = pathlib.Path(os.getenv(\"NH_DATA_DIR\", PROJECT_ROOT / \"data\" / \"raw\"))\n",
    "INTERIM_DIR  = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SIG_PATH  = INTERIM_DIR / \"facility_signatures.csv\"\n",
    "OUT_PATH  = INTERIM_DIR / \"facility_signatures_groupflags.csv\"\n",
    "\n",
    "# Tunables\n",
    "THRESH           = 50.0\n",
    "CUTOFF_DATE      = pd.Timestamp(\"2017-01-01\")\n",
    "LOOK_THROUGH_LLC = True\n",
    "\n",
    "print(\"INPUT :\", SIG_PATH)\n",
    "print(\"OUTPUT:\", OUT_PATH)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Load & detect groups\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "sig = pd.read_csv(SIG_PATH, dtype={\"cms_certification_number\": \"string\"}, low_memory=False)\n",
    "print(f\"[load] {len(sig):,} rows, {sig.shape[1]} cols\")\n",
    "\n",
    "# drop any legacy chow columns\n",
    "sig = sig.loc[:, ~sig.columns.str.startswith(\"chow\")]\n",
    "group_nums = sorted(\n",
    "    int(m.group(1))\n",
    "    for c in sig.columns\n",
    "    if (m := re.search(r\"group(\\d+)_owners$\", c))\n",
    ")\n",
    "print(\"[groups] detected:\", group_nums)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 2) WIDE → LONG\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def split_pipe(s):\n",
    "    return [] if (pd.isna(s) or str(s).strip()==\"\") else [x.strip() for x in str(s).split(\"|\")]\n",
    "\n",
    "_pct_re = re.compile(r\"(\\d+(?:\\.\\d+)?)\")\n",
    "def pct_float(s):\n",
    "    m = _pct_re.search(str(s))\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "recs = []\n",
    "for _, row in sig.iterrows():\n",
    "    ccn  = row[\"cms_certification_number\"]\n",
    "    prov = row.get(\"provider_name\", \"\")\n",
    "    for n in group_nums:\n",
    "        owners = row.get(f\"group{n}_owners\")\n",
    "        pcts   = row.get(f\"group{n}_pcts\")\n",
    "        roles  = row.get(f\"group{n}_roles\")\n",
    "        date   = row.get(f\"group{n}_date\")\n",
    "        if (pd.isna(owners) or owners==\"\") and (pd.isna(date) or date==\"\"):\n",
    "            continue\n",
    "        recs.append((ccn, prov, n, owners, pcts, roles, date))\n",
    "\n",
    "long = pd.DataFrame(recs, columns=[\n",
    "    \"cms_certification_number\",\"provider_name\",\"grp_n\",\n",
    "    \"owners\",\"pcts\",\"roles\",\"date_str\"\n",
    "])\n",
    "long[\"date\"]         = pd.to_datetime(long[\"date_str\"], errors=\"coerce\")\n",
    "long[\"owners_list\"]  = long[\"owners\"].apply(split_pipe)\n",
    "long[\"pcts_list\"]    = long[\"pcts\"].apply(split_pipe)\n",
    "long[\"pcts_num\"]     = long[\"pcts_list\"].apply(lambda lst: [pct_float(x) for x in lst])\n",
    "long[\"roles_list\"]   = long[\"roles\"].apply(split_pipe)\n",
    "\n",
    "# quick alignment check (won't crash, but prints if off)\n",
    "misalign = (\n",
    "    long[\"owners_list\"].str.len() != long[\"pcts_num\"].str.len()\n",
    ") | (\n",
    "    long[\"owners_list\"].str.len() != long[\"roles_list\"].str.len()\n",
    ")\n",
    "mis_ct = int(misalign.sum())\n",
    "print(f\"[align] owner/pct/role length mismatches: {mis_ct}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Normalization (B) + turnover engine\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "LLC_RE          = re.compile(r\"\\b(LLC|INC|CORP|L\\.L\\.C\\.|L\\.P\\.|CO\\.?)\\b\", re.I)\n",
    "CORP_SUFFIX_RE  = re.compile(r\"\\b(CORP(ORATION)?|INCORPORATED|INC|LLC|L\\.L\\.C\\.|LP|L\\.P\\.|CO|COMPANY|HOLDINGS?)\\b\\.?\", re.I)\n",
    "PUNCT_RE        = re.compile(r\"[,\\.&]\")\n",
    "\n",
    "def norm_owner_name(name: str) -> str:\n",
    "    s = str(name).upper().strip()\n",
    "    s = PUNCT_RE.sub(\" \", s)\n",
    "    s = CORP_SUFFIX_RE.sub(\"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def build_dict(row, look_through=True):\n",
    "    owners, pcts, roles = row[\"owners_list\"], row[\"pcts_num\"], row[\"roles_list\"]\n",
    "    any_indirect = any((r or \"\").strip().upper()==\"INDIRECT\" for r in roles)\n",
    "    recs=[]\n",
    "    for o,p,r in zip(owners,pcts,roles):\n",
    "        if np.isnan(p):\n",
    "            continue\n",
    "        # look-through DIRECT corp shells only when INDIRECT detail exists\n",
    "        if look_through and any_indirect and (r or \"\").upper()==\"DIRECT\" and LLC_RE.search(o):\n",
    "            continue\n",
    "        recs.append((norm_owner_name(o), float(p)))\n",
    "    d={}\n",
    "    for o,p in recs:\n",
    "        d[o]=d.get(o,0.0)+p\n",
    "    return d\n",
    "\n",
    "def pct_turnover(prev, curr, look_through=True):\n",
    "    prev_d = build_dict(prev, look_through)\n",
    "    curr_d = build_dict(curr, look_through)\n",
    "    if not prev_d and not curr_d:\n",
    "        return np.nan\n",
    "    owners = set(prev_d) | set(curr_d)\n",
    "    diff   = sum(abs(curr_d.get(o,0.0) - prev_d.get(o,0.0)) for o in owners)\n",
    "    return diff / 2.0\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Collapse same‑day hops (C) and compute turnover\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Keep only the last snapshot per (ccn, date) to avoid double-counting on identical dates\n",
    "long = long.sort_values([\"cms_certification_number\",\"date\",\"grp_n\"])\n",
    "long = long.groupby([\"cms_certification_number\",\"date\"], as_index=False).tail(1).reset_index(drop=True)\n",
    "\n",
    "# surnames for heuristic\n",
    "def surname_set(lst):\n",
    "    out=set()\n",
    "    for n in lst:\n",
    "        n=str(n).strip()\n",
    "        if not n: \n",
    "            continue\n",
    "        out.add((n.split(\",\")[0] if \",\" in n else n.split()[0]).upper())\n",
    "    return out\n",
    "\n",
    "long[\"surnames_set\"] = long[\"owners_list\"].apply(surname_set)\n",
    "\n",
    "# compute raw turnover and basic % presence\n",
    "long[\"turnover\"] = np.nan\n",
    "long[\"has_pct\"]  = long[\"pcts_num\"].apply(lambda lst: sum(pd.notna(x) for x in lst) > 0)\n",
    "\n",
    "pairs = 0\n",
    "for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "    idxs = sorted(idxs)\n",
    "    for i in range(1, len(idxs)):\n",
    "        pairs += 1\n",
    "        long.loc[idxs[i], \"turnover\"] = pct_turnover(\n",
    "            long.loc[idxs[i-1]], long.loc[idxs[i]], look_through=LOOK_THROUGH_LLC\n",
    "        )\n",
    "print(\"[turnover] computed for pairs:\", pairs, \" non-NA:\", int(long[\"turnover\"].notna().sum()))\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 5) A — cautious names-only heuristic when BOTH sides lack %s\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def surname_jaccard(a, b):\n",
    "    if not a and not b:\n",
    "        return np.nan\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b) if (a or b) else 1\n",
    "    return inter / union if union else np.nan\n",
    "\n",
    "long[\"surname_overlap_prev\"]  = False\n",
    "long[\"surname_overlap_ratio\"] = np.nan\n",
    "neither_has_pct = np.zeros(len(long), dtype=bool)\n",
    "\n",
    "for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "    idxs = sorted(idxs)\n",
    "    for i in range(1, len(idxs)):\n",
    "        prev_has = bool(long.loc[idxs[i-1], \"has_pct\"])\n",
    "        curr_has = bool(long.loc[idxs[i],   \"has_pct\"])\n",
    "        neither_has_pct[idxs[i]] = (not prev_has) and (not curr_has)\n",
    "\n",
    "        prev = long.loc[idxs[i-1], \"surnames_set\"]\n",
    "        curr = long.loc[idxs[i],   \"surnames_set\"]\n",
    "        long.loc[idxs[i], \"surname_overlap_prev\"]  = bool(prev & curr)\n",
    "        long.loc[idxs[i], \"surname_overlap_ratio\"] = surname_jaccard(prev, curr)\n",
    "\n",
    "# effective turnover:\n",
    "#   - use numeric turnover when available\n",
    "#   - when turnover is NaN AND neither side has %s:\n",
    "#         if surname overlap is very low (<= 0.25) → proxy 75 (still needs THRESH=50)\n",
    "#         else leave NaN (no CHOW via turnover)\n",
    "long[\"eff_turnover\"] = long[\"turnover\"]\n",
    "mask_nan_t = long[\"eff_turnover\"].isna()\n",
    "use_names  = mask_nan_t & neither_has_pct\n",
    "long.loc[use_names & (long[\"surname_overlap_ratio\"] <= 0.25), \"eff_turnover\"] = 75.0\n",
    "# leave other NaNs as NaN (we do NOT auto-flag)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Flag CHOWs (D + E)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "long[\"is_chow\"]   = False\n",
    "long[\"chow_date\"] = pd.NaT\n",
    "\n",
    "for ccn, idxs in long.groupby(\"cms_certification_number\").groups.items():\n",
    "    idxs = sorted(idxs)\n",
    "\n",
    "    # Group1 = \"new home\" only if:\n",
    "    #   - date >= cutoff\n",
    "    #   - at least one owner % present (avoid placeholder entries)\n",
    "    first = idxs[0]\n",
    "    g1_ok = (\n",
    "        pd.notna(long.loc[first, \"date\"]) and\n",
    "        long.loc[first, \"date\"] >= CUTOFF_DATE and\n",
    "        (sum(pd.notna(long.loc[first, \"pcts_num\"])) > 0)\n",
    "    )\n",
    "    if g1_ok:\n",
    "        long.loc[first, [\"is_chow\", \"chow_date\"]] = [True, long.loc[first, \"date\"]]\n",
    "\n",
    "    # Subsequent groups — unchanged rule, but now using eff_turnover (E)\n",
    "    for i in range(1, len(idxs)):\n",
    "        cond = (\n",
    "            pd.notna(long.loc[idxs[i], \"date\"]) and\n",
    "            long.loc[idxs[i], \"date\"] >= CUTOFF_DATE and\n",
    "            pd.notna(long.loc[idxs[i], \"eff_turnover\"]) and\n",
    "            long.loc[idxs[i], \"eff_turnover\"] >= THRESH\n",
    "        )\n",
    "        if cond:\n",
    "            long.loc[idxs[i], [\"is_chow\", \"chow_date\"]] = [True, long.loc[idxs[i], \"date\"]]\n",
    "\n",
    "print(f\"[flags] total CHOW group rows: {int(long['is_chow'].sum()):,}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Diagnostics (optional but helpful)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "flagged = long[long[\"is_chow\"]].copy()\n",
    "flagged[\"year\"] = pd.to_datetime(flagged[\"chow_date\"]).dt.year\n",
    "by_year = flagged.groupby(\"year\").size().rename(\"flags\").to_frame()\n",
    "\n",
    "# What share relied on names-only heuristic (i.e., raw turnover NaN but eff_turnover set)?\n",
    "flagged[\"via_name_heuristic\"] = flagged[\"turnover\"].isna() & flagged[\"eff_turnover\"].notna()\n",
    "diag = flagged.groupby(\"year\")[\"via_name_heuristic\"].mean().mul(100).round(1).rename(\"% via name heuristic\").to_frame()\n",
    "\n",
    "print(\"\\n[CHOW by year — after A–E fixes]\")\n",
    "print(by_year.join(diag, how=\"left\").fillna(0))\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 8) LONG → WIDE (is_chow, chow_date) and SAVE\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "w_is = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"is_chow\").fillna(False)\n",
    "w_cd = long.pivot(index=\"cms_certification_number\", columns=\"grp_n\", values=\"chow_date\")\n",
    "\n",
    "w_is.columns = [f\"group{n}_is_chow\"   for n in w_is.columns]\n",
    "w_cd.columns = [f\"group{n}_chow_date\" for n in w_cd.columns]\n",
    "w_is = w_is.replace({True: \"Yes\", False: \"\"})\n",
    "\n",
    "sig_chow = (\n",
    "    sig.set_index(\"cms_certification_number\")\n",
    "       .join(w_is, how=\"left\")\n",
    "       .join(w_cd, how=\"left\")\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "# Reorder to keep your familiar sequence\n",
    "def order_cols(df):\n",
    "    grp_nums = sorted(int(re.search(r\"group(\\d+)_owners$\", c).group(1))\n",
    "                      for c in df.columns if re.search(r\"group(\\d+)_owners$\", c))\n",
    "    cols = [\"cms_certification_number\", \"provider_name\"]\n",
    "    for n in grp_nums:\n",
    "        cols += [f\"group{n}_owners\", f\"group{n}_pcts\", f\"group{n}_roles\", f\"group{n}_date\",\n",
    "                 f\"group{n}_is_chow\", f\"group{n}_chow_date\"]\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "sig_chow = sig_chow[order_cols(sig_chow)]\n",
    "sig_chow.to_csv(OUT_PATH, index=False)\n",
    "print(f\"[save] wrote {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8545705-334f-47ed-a81c-bd9cc0afeeab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
