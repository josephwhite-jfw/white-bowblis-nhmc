{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0044b513-8fa0-46a3-b514-3473c00a8633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] C:\\Users\\wrthj\\OneDrive\\NursingHomeData\\ownership-files\\ownership_combined.csv\n",
      "[loaded] rows=5,075,773, cols=7\n",
      "[snapshots built] 40,927 rows\n",
      "[groups] 38,978 group records across CCNs\n",
      "[save] C:\\Repositories\\white-bowblis-nhmc\\data\\interim\\facility_signatures_v3.jsonlists.csv  (rows=14,075)\n",
      "\n",
      "QC — examples:\n",
      "cms_certification_number                                                                         group1_owners              group1_pcts                                     group1_roles group1_start                       group1_snapshot_id        group2_owners group2_pcts group2_roles group2_start                       group2_snapshot_id group3_owners group3_pcts group3_roles group3_start group3_snapshot_id group4_owners group4_pcts group4_roles group4_start group4_snapshot_id group5_owners group5_pcts group5_roles group5_start group5_snapshot_id group6_owners group6_pcts group6_roles group6_start group6_snapshot_id group7_owners group7_pcts group7_roles group7_start group7_snapshot_id group8_owners group8_pcts group8_roles group8_start group8_snapshot_id group9_owners group9_pcts group9_roles group9_start group9_snapshot_id group10_owners group10_pcts group10_roles group10_start group10_snapshot_id group11_owners group11_pcts group11_roles group11_start group11_snapshot_id group12_owners group12_pcts group12_roles group12_start group12_snapshot_id group13_owners group13_pcts group13_roles group13_start group13_snapshot_id group14_owners group14_pcts group14_roles group14_start group14_snapshot_id group15_owners group15_pcts group15_roles group15_start group15_snapshot_id group16_owners group16_pcts group16_roles group16_start group16_snapshot_id\n",
      "                  005125                                                                          [\"VO, TIEN\"]                  [100.0]                                       [\"DIRECT\"]   2016-10-24 081a4929b4563ac8b68226ffa2cd162d3c01cece                  NaN         NaN          NaN          NaT                                      NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN\n",
      "                  005130 [\"BRYN MAWR TRUST\", \"CANYON CREEK HEALTHCARE\", \"FOWLER CARE CENTER\", \"KENWOOD TRUST\"] [null, null, null, null] [\"INDIRECT\", \"INDIRECT\", \"INDIRECT\", \"INDIRECT\"]   2019-05-17 05832ec5404c322148e8ec8ea674b1fd43fdd260                  NaN         NaN          NaN          NaT                                      NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN\n",
      "                  015009                                                 [\"DEARMAN, MARTHA\", \"DEARMAN, LARRY\"]             [81.0, 10.0]                             [\"DIRECT\", \"DIRECT\"]   1969-09-01 d08a870e479ed4a1f5d8fe8420596a3829be6186 [\"DEARMAN, CAMERON\"]       [5.0]   [\"DIRECT\"]   2012-01-25 92a68611718414a2e8d3c15215d1912bdbd82182           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN           NaN         NaN          NaN          NaT                NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN            NaN          NaN           NaN           NaT                 NaN\n",
      "\n",
      "Groups per facility — describe():\n",
      "count    14075.000000\n",
      "mean         2.769307\n",
      "std          2.057058\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         16.000000\n",
      "Top 10 facilities by groups:\n",
      "cms_certification_number\n",
      "495207    16\n",
      "146148    13\n",
      "145000    13\n",
      "395469    13\n",
      "205031    13\n",
      "345172    13\n",
      "396095    13\n",
      "365215    13\n",
      "395536    12\n",
      "495155    12\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Facility Signatures v3 — Stable ownership groups for CHOW analysis\n",
    "#   Input : data/raw/ownership-files/ownership_combined.csv\n",
    "#   Output: data/interim/facility_signatures_v3.jsonlists.csv\n",
    "#\n",
    "# Design:\n",
    "#  - Prefer INDIRECT owners; when present, APPEND DIRECT owners (stable vs level churn)\n",
    "#  - Collapse duplicate owners within snapshot; % = MAX; round; drop tiny stakes\n",
    "#  - Across time: tolerant equality (owner set same & pct diffs ≤ PCT_TOL)\n",
    "#  - New group only if turnover ≥ GROUP_CHANGE_THRESH (≥50% by default)\n",
    "#  - Wide output with JSON lists: groupN_owners, groupN_pcts, groupN_roles, groupN_start, groupN_snapshot_id\n",
    "# ==============================================================================\n",
    "\n",
    "import os, re, json, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Configuration ----------------\n",
    "PCT_ROUND = 1.0          # round each owner's pct to nearest X% (e.g., 1.0 or 0.5)\n",
    "MIN_PCT   = 1.0          # drop owners with pct < MIN_PCT (after rounding)\n",
    "PCT_TOL   = 2.0          # tolerant equality: per-owner pct difference allowed (in points)\n",
    "GROUP_CHANGE_THRESH = 50.0  # require turnover ≥ this to promote a new group\n",
    "\n",
    "# Role priority & merge behavior\n",
    "ROLE_PRIORITY = {\"INDIRECT\": 0, \"DIRECT\": 1, \"PARTNERSHIP\": 2}\n",
    "APPEND_DIRECT_WHEN_INDIRECT = True  # if INDIRECT exists, append DIRECT into same snapshot\n",
    "\n",
    "# ---------------- Paths ----------------\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "while not (PROJECT_ROOT / \"data\").is_dir() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "RAW_DIR     = Path(os.getenv(\"NH_DATA_DIR\", PROJECT_ROOT / \"data\" / \"raw\"))\n",
    "OWN_DIR     = RAW_DIR / \"ownership-files\"\n",
    "INTERIM_DIR = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_COMBINED = OWN_DIR / \"ownership_combined.csv\"\n",
    "OUT_SIG     = INTERIM_DIR / \"facility_signatures_v3.jsonlists.csv\"\n",
    "\n",
    "print(f\"[load] {IN_COMBINED}\")\n",
    "df = pd.read_csv(\n",
    "    IN_COMBINED,\n",
    "    dtype={\"cms_certification_number\": \"string\", \"role\": \"string\",\n",
    "           \"owner_type\": \"string\", \"owner_name\": \"string\"},\n",
    "    parse_dates=[\"association_date\",\"processing_date\"],\n",
    "    low_memory=False,\n",
    ")\n",
    "print(f\"[loaded] rows={len(df):,}, cols={df.shape[1]}\")\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def normalize_role(x: str) -> str:\n",
    "    s = (str(x) if pd.notna(x) else \"\").upper()\n",
    "    if \"INDIRECT\" in s: return \"INDIRECT\"\n",
    "    if \"DIRECT\"   in s: return \"DIRECT\"\n",
    "    if \"PARTNER\"  in s: return \"PARTNERSHIP\"\n",
    "    return \"OTHER\"\n",
    "\n",
    "CORP_SUFFIX_RE = re.compile(\n",
    "    r\"\\b(CORP(ORATION)?|INCORPORATED|INC|LLC|L\\.L\\.C\\.|LP|L\\.P\\.|LLP|CO|COMPANY|HOLDINGS?|INVESTMENTS?)\\b\\.?\",\n",
    "    re.I\n",
    ")\n",
    "def norm_owner_name(name: str) -> str:\n",
    "    s = str(name).upper().strip()\n",
    "    s = re.sub(r\"[,\\.&]\", \" \", s)\n",
    "    s = CORP_SUFFIX_RE.sub(\"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def json_list(values):\n",
    "    out = []\n",
    "    for v in values:\n",
    "        out.append(None if pd.isna(v) else v)\n",
    "    return json.dumps(out, ensure_ascii=False)\n",
    "\n",
    "def make_snapshot_id(level: str, names_norm: list[str], pcts: list[float]) -> str:\n",
    "    payload = json.dumps({\n",
    "        \"level\": level,\n",
    "        \"names\": names_norm,\n",
    "        \"pcts\": [None if pd.isna(x) else float(x) for x in pcts],\n",
    "    }, ensure_ascii=False)\n",
    "    return hashlib.sha1(payload.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# Turnover metrics\n",
    "def pct_turnover(prev_map: dict, next_map: dict) -> float:\n",
    "    names = set(prev_map) | set(next_map)\n",
    "    overlap = 0.0\n",
    "    for n in names:\n",
    "        p = float(prev_map.get(n, 0) or 0)\n",
    "        q = float(next_map.get(n, 0) or 0)\n",
    "        overlap += min(p, q)\n",
    "    base_prev = sum(float(v or 0) for v in prev_map.values())\n",
    "    base_next = sum(float(v or 0) for v in next_map.values())\n",
    "    base = max(base_prev, base_next, 100.0)\n",
    "    if base <= 0:\n",
    "        return 0.0\n",
    "    return float(np.clip(100.0 * (1.0 - overlap / base), 0.0, 100.0))\n",
    "\n",
    "def names_turnover(prev_set: set, next_set: set) -> float:\n",
    "    union = prev_set | next_set\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    inter = prev_set & next_set\n",
    "    return float(np.clip(100.0 * (1 - len(inter)/len(union)), 0.0, 100.0))\n",
    "\n",
    "# Tolerant equality between two compositions\n",
    "def equivalent_compositions(prev_names, prev_pcts, next_names, next_pcts, pct_tol=PCT_TOL) -> bool:\n",
    "    prev_set = set(prev_names)\n",
    "    next_set = set(next_names)\n",
    "    # If name sets differ → not equivalent\n",
    "    if prev_set != next_set:\n",
    "        return False\n",
    "    # If either side lacks usable %s → treat equality by names only\n",
    "    if (prev_pcts is None) or (next_pcts is None):\n",
    "        return True\n",
    "    if any(p is None for p in prev_pcts) or any(q is None for q in next_pcts):\n",
    "        return True\n",
    "    # Compare per-owner pcts with tolerance\n",
    "    pmap = {n: float(p) for n,p in zip(prev_names, prev_pcts)}\n",
    "    qmap = {n: float(q) for n,q in zip(next_names, next_pcts)}\n",
    "    for n in prev_set:\n",
    "        if abs(pmap.get(n, 0.0) - qmap.get(n, 0.0)) > pct_tol:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ---------------- Basic hygiene ----------------\n",
    "df[\"cms_certification_number\"] = (\n",
    "    df[\"cms_certification_number\"].astype(\"string\")\n",
    "      .str.replace(r\"\\D\",\"\",regex=True).str.zfill(6)\n",
    ")\n",
    "df[\"role_norm\"]  = df[\"role\"].map(normalize_role)\n",
    "df[\"owner_norm\"] = df[\"owner_name\"].map(norm_owner_name)\n",
    "\n",
    "# association_date fallback to processing_date if missing\n",
    "if \"association_date\" in df.columns:\n",
    "    df[\"association_date\"] = df[\"association_date\"].fillna(df[\"processing_date\"])\n",
    "else:\n",
    "    df[\"association_date\"] = df[\"processing_date\"]\n",
    "\n",
    "# Robust % to numeric\n",
    "pct_raw = (df[\"ownership_percentage\"].astype(str)\n",
    "           .str.replace(\"%\",\"\",regex=False)\n",
    "           .str.replace(\",\",\"\",regex=False)\n",
    "           .str.strip())\n",
    "df[\"pct_num_raw\"] = pd.to_numeric(pct_raw, errors=\"coerce\")\n",
    "\n",
    "# ---------------- Build per (CCN, assoc_date) snapshot with level handling ----------------\n",
    "snap_rows = []\n",
    "for (ccn, adate), g in df.groupby([\"cms_certification_number\",\"association_date\"], sort=True):\n",
    "    if pd.isna(ccn) or pd.isna(adate):\n",
    "        continue\n",
    "    g = g.copy()\n",
    "\n",
    "    # Which levels exist?\n",
    "    levels_present = set(g[\"role_norm\"].dropna().unique().tolist())\n",
    "    used_level = None\n",
    "\n",
    "    # Start with INDIRECT if present\n",
    "    parts = []\n",
    "    if \"INDIRECT\" in levels_present:\n",
    "        used_level = \"INDIRECT\"\n",
    "        parts.append(g[g[\"role_norm\"] == \"INDIRECT\"])\n",
    "        if APPEND_DIRECT_WHEN_INDIRECT and \"DIRECT\" in levels_present:\n",
    "            parts.append(g[g[\"role_norm\"] == \"DIRECT\"])\n",
    "    elif \"DIRECT\" in levels_present:\n",
    "        used_level = \"DIRECT\"\n",
    "        parts.append(g[g[\"role_norm\"] == \"DIRECT\"])\n",
    "    elif \"PARTNERSHIP\" in levels_present:\n",
    "        used_level = \"PARTNERSHIP\"\n",
    "        parts.append(g[g[\"role_norm\"] == \"PARTNERSHIP\"])\n",
    "    else:\n",
    "        # no recognized level → skip\n",
    "        continue\n",
    "\n",
    "    sel = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "    # Collapse duplicate owners within snapshot (by owner_norm, owner_type)\n",
    "    # pct = MAX, then round & drop tiny stakes\n",
    "    agg = (sel.groupby([\"owner_norm\",\"owner_type\"], dropna=False, as_index=False)\n",
    "              .agg(owner_name=(\"owner_name\",\"first\"),\n",
    "                   pct=(\"pct_num_raw\",\"max\"),\n",
    "                   role=(\"role_norm\",\"first\")))\n",
    "\n",
    "    # Round and drop small\n",
    "    agg[\"pct\"] = agg[\"pct\"].round(3)  # safe before rounding step\n",
    "    if PCT_ROUND is not None and PCT_ROUND > 0:\n",
    "        agg[\"pct\"] = (np.round(agg[\"pct\"] / PCT_ROUND) * PCT_ROUND)\n",
    "    agg.loc[agg[\"pct\"] < MIN_PCT, \"pct\"] = np.nan  # treat as missing, then drop\n",
    "    agg = agg[~agg[\"pct\"].isna()].copy()\n",
    "\n",
    "    # If everything dropped (all tiny/NaN), keep names with pct=None for names-only comparison\n",
    "    if agg.empty:\n",
    "        # use distinct names from sel\n",
    "        names_norm = sorted(set(sel[\"owner_norm\"].dropna().tolist()))\n",
    "        names_raw  = names_norm  # fallback raw ≈ norm\n",
    "        roles_list = [used_level] * len(names_norm)\n",
    "        types_list = [None] * len(names_norm)\n",
    "        pcts_list  = [None] * len(names_norm)\n",
    "    else:\n",
    "        # Sort by pct desc, then name asc — stable\n",
    "        agg = agg.sort_values([\"pct\",\"owner_norm\"], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
    "        names_norm = agg[\"owner_norm\"].tolist()\n",
    "        names_raw  = agg[\"owner_name\"].tolist()\n",
    "        roles_list = [used_level] * len(agg)\n",
    "        types_list = agg[\"owner_type\"].tolist()\n",
    "        pcts_list  = agg[\"pct\"].astype(float).tolist()\n",
    "\n",
    "    snap_rows.append({\n",
    "        \"cms_certification_number\": ccn,\n",
    "        \"association_date\": pd.to_datetime(adate),\n",
    "        \"used_level\": used_level,\n",
    "        \"owner_names\": json_list(names_raw),\n",
    "        \"name_norms\": json_list(names_norm),\n",
    "        \"owner_types\": json_list(types_list),\n",
    "        \"roles\": json_list(roles_list),\n",
    "        \"ownership_percentages\": json_list([None if pd.isna(x) else float(x) for x in pcts_list]),\n",
    "    })\n",
    "\n",
    "snap = (pd.DataFrame(snap_rows)\n",
    "          .sort_values([\"cms_certification_number\",\"association_date\"])\n",
    "          .reset_index(drop=True))\n",
    "print(f\"[snapshots built] {len(snap):,} rows\")\n",
    "\n",
    "# ---------------- Build stable groups per CCN with tolerant equality + turnover rule ----------------\n",
    "def _parse(js):\n",
    "    try:\n",
    "        return json.loads(js) if isinstance(js, str) else (js if isinstance(js, list) else [])\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "groups = []\n",
    "for ccn, g in snap.groupby(\"cms_certification_number\", sort=True):\n",
    "    g = g.sort_values(\"association_date\").reset_index(drop=True)\n",
    "    if g.empty:\n",
    "        continue\n",
    "\n",
    "    # Seed with first snapshot\n",
    "    first = g.iloc[0]\n",
    "    cur_names = _parse(first[\"name_norms\"])\n",
    "    cur_pcts  = [None if x is None else float(x) for x in _parse(first[\"ownership_percentages\"])]\n",
    "    cur_level = str(first[\"used_level\"])\n",
    "    cur_start = pd.to_datetime(first[\"association_date\"])\n",
    "\n",
    "    def _sid(level, names, pcts):\n",
    "        payload = json.dumps({\"level\": level, \"names\": names, \"pcts\": pcts}, ensure_ascii=False)\n",
    "        return hashlib.sha1(payload.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    groups.append({\n",
    "        \"cms_certification_number\": ccn,\n",
    "        \"group_n\": 1,\n",
    "        \"owners\": json_list(_parse(first[\"owner_names\"])),\n",
    "        \"names\": json_list(cur_names),\n",
    "        \"pcts\": json_list(cur_pcts),\n",
    "        \"roles\": json_list([cur_level]*len(cur_names)),\n",
    "        \"start\": cur_start,\n",
    "        \"snapshot_id\": _sid(cur_level, cur_names, cur_pcts),\n",
    "    })\n",
    "    grp_n = 1\n",
    "\n",
    "    # Walk forward\n",
    "    for i in range(1, len(g)):\n",
    "        row = g.iloc[i]\n",
    "        nxt_names = _parse(row[\"name_norms\"])\n",
    "        nxt_pcts  = [None if x is None else float(x) for x in _parse(row[\"ownership_percentages\"])]\n",
    "        nxt_level = str(row[\"used_level\"])\n",
    "        nxt_start = pd.to_datetime(row[\"association_date\"])\n",
    "\n",
    "        # Decide if the new snapshot should start a new group\n",
    "        same_enough = equivalent_compositions(cur_names, cur_pcts, nxt_names, nxt_pcts, pct_tol=PCT_TOL)\n",
    "\n",
    "        if same_enough:\n",
    "            # Keep current group; do not promote\n",
    "            continue\n",
    "\n",
    "        # Not equivalent — check turnover threshold (percent if usable, else names)\n",
    "        prev_map = {n:p for n,p in zip(cur_names, cur_pcts) if p is not None}\n",
    "        next_map = {n:p for n,p in zip(nxt_names, nxt_pcts) if p is not None}\n",
    "        prev_has = (len(prev_map) > 0)\n",
    "        next_has = (len(next_map) > 0)\n",
    "        if prev_has and next_has and all(p is not None for p in cur_pcts) and all(q is not None for q in nxt_pcts):\n",
    "            turn = pct_turnover(prev_map, next_map)\n",
    "        else:\n",
    "            turn = names_turnover(set(cur_names), set(nxt_names))\n",
    "\n",
    "        if turn < GROUP_CHANGE_THRESH:\n",
    "            # Below threshold → treat as the same group (update “current” to latest snapshot)\n",
    "            cur_names, cur_pcts, cur_level = nxt_names, nxt_pcts, nxt_level\n",
    "            continue\n",
    "\n",
    "        # Promote to a NEW group\n",
    "        grp_n += 1\n",
    "        groups.append({\n",
    "            \"cms_certification_number\": ccn,\n",
    "            \"group_n\": grp_n,\n",
    "            \"owners\": json_list(_parse(row[\"owner_names\"])),\n",
    "            \"names\": json_list(nxt_names),\n",
    "            \"pcts\": json_list(nxt_pcts),\n",
    "            \"roles\": json_list([nxt_level]*len(nxt_names)),\n",
    "            \"start\": nxt_start,\n",
    "            \"snapshot_id\": _sid(nxt_level, nxt_names, nxt_pcts),\n",
    "        })\n",
    "        # Reset current to the new group's composition\n",
    "        cur_names, cur_pcts, cur_level = nxt_names, nxt_pcts, nxt_level\n",
    "\n",
    "groups_long = pd.DataFrame(groups).sort_values([\"cms_certification_number\",\"group_n\"]).reset_index(drop=True)\n",
    "print(f\"[groups] {len(groups_long):,} group records across CCNs\")\n",
    "\n",
    "# ---------------- Pivot wide (grouped columns together) ----------------\n",
    "def pivot_block(s: pd.DataFrame, value_col: str, prefix: str):\n",
    "    wide = s.pivot(index=\"cms_certification_number\", columns=\"group_n\", values=value_col)\n",
    "    wide.columns = [f\"{prefix}{i}\" for i in wide.columns]\n",
    "    return wide\n",
    "\n",
    "w_owners = pivot_block(groups_long, \"owners\",      \"group\")\n",
    "w_pcts   = pivot_block(groups_long, \"pcts\",        \"group\")\n",
    "w_roles  = pivot_block(groups_long, \"roles\",       \"group\")\n",
    "w_start  = pivot_block(groups_long, \"start\",       \"group\")\n",
    "w_hash   = pivot_block(groups_long, \"snapshot_id\", \"group\")\n",
    "\n",
    "def rename_block(df_block, suffix):\n",
    "    return df_block.rename(columns={c: f\"{c}_{suffix}\" for c in df_block.columns})\n",
    "\n",
    "owners_block = rename_block(w_owners, \"owners\")\n",
    "pcts_block   = rename_block(w_pcts,   \"pcts\")\n",
    "roles_block  = rename_block(w_roles,  \"roles\")\n",
    "start_block  = rename_block(w_start,  \"start\")\n",
    "id_block     = rename_block(w_hash,   \"snapshot_id\")\n",
    "\n",
    "all_groups = sorted({int(c.replace(\"group\",\"\").split(\"_\")[0]) for c in owners_block.columns})\n",
    "ordered_cols = [\"cms_certification_number\"]\n",
    "for i in all_groups:\n",
    "    ordered_cols += [f\"group{i}_owners\", f\"group{i}_pcts\", f\"group{i}_roles\", f\"group{i}_start\", f\"group{i}_snapshot_id\"]\n",
    "\n",
    "wide = (pd.concat([owners_block, pcts_block, roles_block, start_block, id_block], axis=1)\n",
    "          .reset_index())\n",
    "wide = wide.reindex(columns=[c for c in ordered_cols if c in wide.columns])\n",
    "\n",
    "# ---------------- Save ----------------\n",
    "wide.to_csv(OUT_SIG, index=False, date_format=\"%Y-%m-%d\")\n",
    "print(f\"[save] {OUT_SIG}  (rows={len(wide):,})\")\n",
    "\n",
    "# ---------------- Quick QC ----------------\n",
    "print(\"\\nQC — examples:\")\n",
    "with pd.option_context(\"display.max_colwidth\", 100):\n",
    "    print(wide.head(3).to_string(index=False))\n",
    "\n",
    "# Distribution of number of groups per CCN\n",
    "grp_counts = groups_long.groupby(\"cms_certification_number\")[\"group_n\"].max()\n",
    "print(\"\\nGroups per facility — describe():\")\n",
    "print(grp_counts.describe().to_string())\n",
    "print(\"Top 10 facilities by groups:\")\n",
    "print(grp_counts.sort_values(ascending=False).head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0aa7c3-aa67-4acc-9b71-3b6ca94f261f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
